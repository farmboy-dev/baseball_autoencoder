{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('player_stat_.csv')\n",
    "data = data.drop(['player'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>SV</th>\n",
       "      <th>HLD</th>\n",
       "      <th>IP</th>\n",
       "      <th>BF</th>\n",
       "      <th>H</th>\n",
       "      <th>HR</th>\n",
       "      <th>SO</th>\n",
       "      <th>BB</th>\n",
       "      <th>R</th>\n",
       "      <th>ER</th>\n",
       "      <th>K/9</th>\n",
       "      <th>BB/9</th>\n",
       "      <th>K%</th>\n",
       "      <th>BB%</th>\n",
       "      <th>AVG</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LOB%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>FIP</th>\n",
       "      <th>LL</th>\n",
       "      <th>PF</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hyun-Jin Ryu</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182.2</td>\n",
       "      <td>734</td>\n",
       "      <td>153</td>\n",
       "      <td>12</td>\n",
       "      <td>210</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>54</td>\n",
       "      <td>10.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.232</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.780</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0250</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yu Darvish</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>885</td>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>276</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>10.71</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.817</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Merrill Kelly</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158.1</td>\n",
       "      <td>674</td>\n",
       "      <td>152</td>\n",
       "      <td>18</td>\n",
       "      <td>161</td>\n",
       "      <td>47</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>9.15</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.260</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.717</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kwang Hyun Kim</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190.1</td>\n",
       "      <td>786</td>\n",
       "      <td>198</td>\n",
       "      <td>13</td>\n",
       "      <td>180</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>53</td>\n",
       "      <td>8.51</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1.240</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.792</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Josh Lindblom</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194.2</td>\n",
       "      <td>773</td>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>189</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>8.74</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.226</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.787</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Masahiro Tanaka</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>822</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>183</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>7.77</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kenta Maeda</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206.3</td>\n",
       "      <td>821</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>7.63</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.222</td>\n",
       "      <td>1.013</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.798</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shohei Ohtani</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>548</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>11.19</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.799</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yusei Kikuchi</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.7</td>\n",
       "      <td>654</td>\n",
       "      <td>124</td>\n",
       "      <td>16</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>8.41</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.757</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0450</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yoshihisa Hirano</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>57.3</td>\n",
       "      <td>240</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.266</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.821</td>\n",
       "      <td>2.67</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shun Yamaguchi</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>705</td>\n",
       "      <td>137</td>\n",
       "      <td>8</td>\n",
       "      <td>188</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>9.95</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.222</td>\n",
       "      <td>1.159</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.755</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.1023</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hisashi Iwakuma</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>471</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>6.81</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.244</td>\n",
       "      <td>1.050</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.789</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kyuji Fujikawa</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>47.7</td>\n",
       "      <td>189</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10.95</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.207</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.885</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>745</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>187</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>8.95</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.786</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              player   G  GS  CG  SHO   W  L  SV  HLD     IP   BF    H  HR  \\\n",
       "0       Hyun-Jin Ryu  27  27   1    0   9  9   0    0  182.2  734  153  12   \n",
       "1         Yu Darvish  28  28  10    6  18  6   0    0  232.0  885  156   5   \n",
       "2      Merrill Kelly  28  28   0    0  12  7   0    0  158.1  674  152  18   \n",
       "3     Kwang Hyun Kim  31  30   0    0  17  6   0    0  190.1  786  198  13   \n",
       "4      Josh Lindblom  30  30   0    0  20  3   0    0  194.2  773  165  13   \n",
       "5    Masahiro Tanaka  28  27   8    2  24  0   1    0  212.0  822  168   6   \n",
       "6        Kenta Maeda  29  29   5    0  15  8   0    0  206.3  821  168   5   \n",
       "7      Shohei Ohtani  21  10   0    1  10  4   0    1  140.0  548   89   4   \n",
       "8      Yusei Kikuchi  23  23   1    0  14  4   0    0  163.7  654  124  16   \n",
       "9   Yoshihisa Hirano  58   0   0    0   3  7  29    8   57.3  240   57   5   \n",
       "10    Shun Yamaguchi  26  26   0    0  15  4   0    0  170.0  705  137   8   \n",
       "11   Hisashi Iwakuma  17  17   2    1   6  7   0    0  119.0  471  106   6   \n",
       "12    Kyuji Fujikawa  48   0   0    0   2  2  24    2   47.7  189   34   1   \n",
       "13     Miles Mikolas  27  27   0    0  14  8   0    0  188.0  745  162  10   \n",
       "\n",
       "     SO  BB   R  ER    K/9  BB/9     K%    BB%    AVG   WHIP  BABIP   LOB%  \\\n",
       "0   210  58  58  54  10.35  2.27  0.286  0.063  0.232  1.090  0.320  0.780   \n",
       "1   276  36  42  37  10.71  1.40  0.312  0.041  0.190  0.828  0.280  0.817   \n",
       "2   161  47  78  72   9.15  2.67  0.239  0.070  0.250  1.260  0.309  0.717   \n",
       "3   180  38  64  53   8.51  1.80  0.229  0.048  0.270  1.240  0.338  0.792   \n",
       "4   189  29  57  54   8.74  1.34  0.245  0.038  0.226  1.000  0.285  0.787   \n",
       "5   183  32  35  30   7.77  1.36  0.223  0.039  0.218  0.943  0.278  0.863   \n",
       "6   175  41  49  48   7.63  1.79  0.213  0.050  0.222  1.013  0.282  0.798   \n",
       "7   174  45  33  29  11.19  2.89  0.318  0.082  0.184  0.957  0.277  0.799   \n",
       "8   153  45  59  56   8.41  2.47  0.234  0.069  0.210  1.033  0.256  0.757   \n",
       "9    47  16  19  17   7.38  2.51  0.196  0.067  0.266  1.273  0.321  0.821   \n",
       "10  188  60  60  55   9.95  3.18  0.267  0.085  0.222  1.159  0.306  0.755   \n",
       "11   90  19  34  32   6.81  1.44  0.191  0.040  0.244  1.050  0.296  0.789   \n",
       "12   58  15   7   7  10.95  2.83  0.307  0.079  0.207  1.028  0.314  0.885   \n",
       "13  187  23  53  47   8.95  1.10  0.251  0.031  0.233  0.984  0.305  0.786   \n",
       "\n",
       "     ERA   FIP    LL      PF  WAR  \n",
       "0   2.66  2.41  0.50  1.0250  3.8  \n",
       "1   1.44  1.46  0.75  0.9870  4.7  \n",
       "2   4.09  4.40  0.50  0.9710  2.0  \n",
       "3   2.51  2.77  0.50  0.9710  0.6  \n",
       "4   2.50  2.87  0.50  0.9380  0.8  \n",
       "5   1.27  2.35  0.75  1.0010  2.9  \n",
       "6   2.09  2.38  0.75  0.9950  2.9  \n",
       "7   1.86  2.28  0.75  0.9870  1.0  \n",
       "8   3.08  3.52  0.75  1.0450  0.2  \n",
       "9   2.67  3.58  0.75  0.9870  0.3  \n",
       "10  2.91  3.07  0.75  1.1023 -0.4  \n",
       "11  2.42  2.88  0.75  1.0010  0.9  \n",
       "12  1.32  1.55  0.75  0.9580  0.2  \n",
       "13  2.25  2.54  0.75  1.0230  4.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "data = pd.read_csv('player_stat_.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24390244, 0.9       , 0.1       , 0.        , 0.31818182,\n",
       "        1.        , 0.        , 0.        , 0.72978839, 0.78304598,\n",
       "        0.72560976, 0.64705882, 0.71179039, 0.95555556, 0.71830986,\n",
       "        0.72307692, 0.80821918, 0.5625    , 0.7480315 , 0.59259259,\n",
       "        0.55813953, 0.58876404, 0.7804878 , 0.375     , 0.4929078 ,\n",
       "        0.32312925, 0.        , 0.52951917, 0.82352941],\n",
       "       [0.26829268, 0.93333333, 1.        , 1.        , 0.72727273,\n",
       "        0.66666667, 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.74390244, 0.23529412, 1.        , 0.46666667, 0.49295775,\n",
       "        0.46153846, 0.89041096, 0.14423077, 0.95275591, 0.18518519,\n",
       "        0.06976744, 0.        , 0.29268293, 0.5952381 , 0.06028369,\n",
       "        0.        , 1.        , 0.29823494, 1.        ],\n",
       "       [0.26829268, 0.93333333, 0.        , 0.        , 0.45454545,\n",
       "        0.77777778, 0.        , 0.        , 0.59902333, 0.69683908,\n",
       "        0.7195122 , 1.        , 0.49781659, 0.71111111, 1.        ,\n",
       "        1.        , 0.53424658, 0.75480769, 0.37795276, 0.72222222,\n",
       "        0.76744186, 0.97078652, 0.64634146, 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.2008521 , 0.47058824],\n",
       "       [0.34146341, 1.        , 0.        , 0.        , 0.68181818,\n",
       "        0.66666667, 0.        , 0.        , 0.77265328, 0.85775862,\n",
       "        1.        , 0.70588235, 0.58078603, 0.51111111, 0.8028169 ,\n",
       "        0.70769231, 0.38812785, 0.33653846, 0.2992126 , 0.31481481,\n",
       "        1.        , 0.9258427 , 1.        , 0.44642857, 0.43971631,\n",
       "        0.44557823, 0.        , 0.2008521 , 0.19607843],\n",
       "       [0.31707317, 1.        , 0.        , 0.        , 0.81818182,\n",
       "        0.33333333, 0.        , 0.        , 0.79489962, 0.83908046,\n",
       "        0.79878049, 0.70588235, 0.62008734, 0.31111111, 0.70422535,\n",
       "        0.72307692, 0.44063927, 0.11538462, 0.42519685, 0.12962963,\n",
       "        0.48837209, 0.38651685, 0.35365854, 0.41666667, 0.43617021,\n",
       "        0.47959184, 0.        , 0.        , 0.23529412],\n",
       "       [0.26829268, 0.9       , 0.8       , 0.33333333, 1.        ,\n",
       "        0.        , 0.03448276, 0.        , 0.89148128, 0.90948276,\n",
       "        0.81707317, 0.29411765, 0.59388646, 0.37777778, 0.3943662 ,\n",
       "        0.35384615, 0.21917808, 0.125     , 0.2519685 , 0.14814815,\n",
       "        0.39534884, 0.25842697, 0.26829268, 0.86904762, 0.        ,\n",
       "        0.30272109, 1.        , 0.38344492, 0.64705882],\n",
       "       [0.29268293, 0.96666667, 0.5       , 0.        , 0.59090909,\n",
       "        0.88888889, 0.        , 0.        , 0.86055345, 0.90804598,\n",
       "        0.81707317, 0.23529412, 0.55895197, 0.57777778, 0.5915493 ,\n",
       "        0.63076923, 0.18721461, 0.33173077, 0.17322835, 0.35185185,\n",
       "        0.44186047, 0.41573034, 0.31707317, 0.48214286, 0.29078014,\n",
       "        0.31292517, 1.        , 0.34692635, 0.64705882],\n",
       "       [0.09756098, 0.33333333, 0.        , 0.16666667, 0.36363636,\n",
       "        0.44444444, 0.        , 0.125     , 0.50081389, 0.5158046 ,\n",
       "        0.33536585, 0.17647059, 0.55458515, 0.66666667, 0.36619718,\n",
       "        0.33846154, 1.        , 0.86057692, 1.        , 0.94444444,\n",
       "        0.        , 0.28988764, 0.25609756, 0.48809524, 0.20921986,\n",
       "        0.27891156, 1.        , 0.29823494, 0.2745098 ],\n",
       "       [0.14634146, 0.76666667, 0.1       , 0.        , 0.54545455,\n",
       "        0.44444444, 0.        , 0.        , 0.62940857, 0.66810345,\n",
       "        0.54878049, 0.88235294, 0.4628821 , 0.66666667, 0.73239437,\n",
       "        0.75384615, 0.3652968 , 0.65865385, 0.33858268, 0.7037037 ,\n",
       "        0.30232558, 0.46067416, 0.        , 0.23809524, 0.64184397,\n",
       "        0.70068027, 1.        , 0.65124772, 0.11764706],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.04545455,\n",
       "        0.77777778, 1.        , 1.        , 0.05208899, 0.07327586,\n",
       "        0.1402439 , 0.23529412, 0.        , 0.02222222, 0.16901408,\n",
       "        0.15384615, 0.13013699, 0.67788462, 0.03937008, 0.66666667,\n",
       "        0.95348837, 1.        , 0.79268293, 0.61904762, 0.4964539 ,\n",
       "        0.72108844, 1.        , 0.29823494, 0.1372549 ],\n",
       "       [0.2195122 , 0.86666667, 0.        , 0.        , 0.59090909,\n",
       "        0.44444444, 0.        , 0.        , 0.66359197, 0.74137931,\n",
       "        0.62804878, 0.41176471, 0.61572052, 1.        , 0.74647887,\n",
       "        0.73846154, 0.71689498, 1.        , 0.5984252 , 1.        ,\n",
       "        0.44186047, 0.74382022, 0.6097561 , 0.22619048, 0.58156028,\n",
       "        0.54761905, 1.        , 1.        , 0.        ],\n",
       "       [0.        , 0.56666667, 0.2       , 0.16666667, 0.18181818,\n",
       "        0.77777778, 0.        , 0.        , 0.38686923, 0.40517241,\n",
       "        0.43902439, 0.29411765, 0.18777293, 0.08888889, 0.38028169,\n",
       "        0.38461538, 0.        , 0.16346154, 0.        , 0.16666667,\n",
       "        0.69767442, 0.4988764 , 0.48780488, 0.42857143, 0.40780142,\n",
       "        0.4829932 , 1.        , 0.38344492, 0.25490196],\n",
       "       [0.75609756, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.22222222, 0.82758621, 0.25      , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04803493, 0.        , 0.        ,\n",
       "        0.        , 0.94520548, 0.83173077, 0.91338583, 0.88888889,\n",
       "        0.26744186, 0.4494382 , 0.70731707, 1.        , 0.0177305 ,\n",
       "        0.03061224, 1.        , 0.12172855, 0.11764706],\n",
       "       [0.24390244, 0.9       , 0.        , 0.        , 0.54545455,\n",
       "        0.88888889, 0.        , 0.        , 0.76125882, 0.79885057,\n",
       "        0.7804878 , 0.52941176, 0.61135371, 0.17777778, 0.64788732,\n",
       "        0.61538462, 0.48858447, 0.        , 0.47244094, 0.        ,\n",
       "        0.56976744, 0.3505618 , 0.59756098, 0.41071429, 0.34751773,\n",
       "        0.36734694, 1.        , 0.51734632, 0.90196078]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm = (data - data.min()) / (data.max() - data.min())\n",
    "data_norm = data_norm.to_numpy()\n",
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_1 = torch.FloatTensor(data_norm[0:8])\n",
    "test_set_1 = torch.FloatTensor(data_norm[8:14])\n",
    "# test_set_1 = torch[8:14]\n",
    "# training_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_player = len(training_set_1)\n",
    "nb_stats = data_norm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(29, 15)\n",
    "        self.fc2 = nn.Linear(15, 5)\n",
    "        self.fc3 = nn.Linear(5, 15)\n",
    "        self.fc4 = nn.Linear(15, 29)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.2309)\n",
      "epoch: 2 loss: tensor(0.2308)\n",
      "epoch: 3 loss: tensor(0.2308)\n",
      "epoch: 4 loss: tensor(0.2309)\n",
      "epoch: 5 loss: tensor(0.2311)\n",
      "epoch: 6 loss: tensor(0.2309)\n",
      "epoch: 7 loss: tensor(0.2306)\n",
      "epoch: 8 loss: tensor(0.2305)\n",
      "epoch: 9 loss: tensor(0.2304)\n",
      "epoch: 10 loss: tensor(0.2305)\n",
      "epoch: 11 loss: tensor(0.2308)\n",
      "epoch: 12 loss: tensor(0.2307)\n",
      "epoch: 13 loss: tensor(0.2304)\n",
      "epoch: 14 loss: tensor(0.2302)\n",
      "epoch: 15 loss: tensor(0.2301)\n",
      "epoch: 16 loss: tensor(0.2300)\n",
      "epoch: 17 loss: tensor(0.2301)\n",
      "epoch: 18 loss: tensor(0.2301)\n",
      "epoch: 19 loss: tensor(0.2298)\n",
      "epoch: 20 loss: tensor(0.2298)\n",
      "epoch: 21 loss: tensor(0.2298)\n",
      "epoch: 22 loss: tensor(0.2297)\n",
      "epoch: 23 loss: tensor(0.2298)\n",
      "epoch: 24 loss: tensor(0.2298)\n",
      "epoch: 25 loss: tensor(0.2296)\n",
      "epoch: 26 loss: tensor(0.2294)\n",
      "epoch: 27 loss: tensor(0.2294)\n",
      "epoch: 28 loss: tensor(0.2295)\n",
      "epoch: 29 loss: tensor(0.2293)\n",
      "epoch: 30 loss: tensor(0.2292)\n",
      "epoch: 31 loss: tensor(0.2291)\n",
      "epoch: 32 loss: tensor(0.2291)\n",
      "epoch: 33 loss: tensor(0.2291)\n",
      "epoch: 34 loss: tensor(0.2290)\n",
      "epoch: 35 loss: tensor(0.2289)\n",
      "epoch: 36 loss: tensor(0.2288)\n",
      "epoch: 37 loss: tensor(0.2287)\n",
      "epoch: 38 loss: tensor(0.2286)\n",
      "epoch: 39 loss: tensor(0.2286)\n",
      "epoch: 40 loss: tensor(0.2285)\n",
      "epoch: 41 loss: tensor(0.2284)\n",
      "epoch: 42 loss: tensor(0.2283)\n",
      "epoch: 43 loss: tensor(0.2282)\n",
      "epoch: 44 loss: tensor(0.2281)\n",
      "epoch: 45 loss: tensor(0.2281)\n",
      "epoch: 46 loss: tensor(0.2280)\n",
      "epoch: 47 loss: tensor(0.2279)\n",
      "epoch: 48 loss: tensor(0.2277)\n",
      "epoch: 49 loss: tensor(0.2276)\n",
      "epoch: 50 loss: tensor(0.2275)\n",
      "epoch: 51 loss: tensor(0.2275)\n",
      "epoch: 52 loss: tensor(0.2274)\n",
      "epoch: 53 loss: tensor(0.2272)\n",
      "epoch: 54 loss: tensor(0.2271)\n",
      "epoch: 55 loss: tensor(0.2270)\n",
      "epoch: 56 loss: tensor(0.2269)\n",
      "epoch: 57 loss: tensor(0.2268)\n",
      "epoch: 58 loss: tensor(0.2266)\n",
      "epoch: 59 loss: tensor(0.2265)\n",
      "epoch: 60 loss: tensor(0.2263)\n",
      "epoch: 61 loss: tensor(0.2262)\n",
      "epoch: 62 loss: tensor(0.2260)\n",
      "epoch: 63 loss: tensor(0.2259)\n",
      "epoch: 64 loss: tensor(0.2258)\n",
      "epoch: 65 loss: tensor(0.2256)\n",
      "epoch: 66 loss: tensor(0.2254)\n",
      "epoch: 67 loss: tensor(0.2252)\n",
      "epoch: 68 loss: tensor(0.2251)\n",
      "epoch: 69 loss: tensor(0.2249)\n",
      "epoch: 70 loss: tensor(0.2248)\n",
      "epoch: 71 loss: tensor(0.2245)\n",
      "epoch: 72 loss: tensor(0.2243)\n",
      "epoch: 73 loss: tensor(0.2241)\n",
      "epoch: 74 loss: tensor(0.2239)\n",
      "epoch: 75 loss: tensor(0.2237)\n",
      "epoch: 76 loss: tensor(0.2235)\n",
      "epoch: 77 loss: tensor(0.2233)\n",
      "epoch: 78 loss: tensor(0.2231)\n",
      "epoch: 79 loss: tensor(0.2228)\n",
      "epoch: 80 loss: tensor(0.2226)\n",
      "epoch: 81 loss: tensor(0.2224)\n",
      "epoch: 82 loss: tensor(0.2221)\n",
      "epoch: 83 loss: tensor(0.2219)\n",
      "epoch: 84 loss: tensor(0.2216)\n",
      "epoch: 85 loss: tensor(0.2213)\n",
      "epoch: 86 loss: tensor(0.2210)\n",
      "epoch: 87 loss: tensor(0.2208)\n",
      "epoch: 88 loss: tensor(0.2205)\n",
      "epoch: 89 loss: tensor(0.2202)\n",
      "epoch: 90 loss: tensor(0.2198)\n",
      "epoch: 91 loss: tensor(0.2195)\n",
      "epoch: 92 loss: tensor(0.2192)\n",
      "epoch: 93 loss: tensor(0.2189)\n",
      "epoch: 94 loss: tensor(0.2186)\n",
      "epoch: 95 loss: tensor(0.2183)\n",
      "epoch: 96 loss: tensor(0.2179)\n",
      "epoch: 97 loss: tensor(0.2174)\n",
      "epoch: 98 loss: tensor(0.2171)\n",
      "epoch: 99 loss: tensor(0.2168)\n",
      "epoch: 100 loss: tensor(0.2165)\n",
      "epoch: 101 loss: tensor(0.2162)\n",
      "epoch: 102 loss: tensor(0.2157)\n",
      "epoch: 103 loss: tensor(0.2152)\n",
      "epoch: 104 loss: tensor(0.2149)\n",
      "epoch: 105 loss: tensor(0.2146)\n",
      "epoch: 106 loss: tensor(0.2143)\n",
      "epoch: 107 loss: tensor(0.2138)\n",
      "epoch: 108 loss: tensor(0.2132)\n",
      "epoch: 109 loss: tensor(0.2126)\n",
      "epoch: 110 loss: tensor(0.2124)\n",
      "epoch: 111 loss: tensor(0.2122)\n",
      "epoch: 112 loss: tensor(0.2119)\n",
      "epoch: 113 loss: tensor(0.2117)\n",
      "epoch: 114 loss: tensor(0.2113)\n",
      "epoch: 115 loss: tensor(0.2100)\n",
      "epoch: 116 loss: tensor(0.2098)\n",
      "epoch: 117 loss: tensor(0.2105)\n",
      "epoch: 118 loss: tensor(0.2103)\n",
      "epoch: 119 loss: tensor(0.2104)\n",
      "epoch: 120 loss: tensor(0.2103)\n",
      "epoch: 121 loss: tensor(0.2095)\n",
      "epoch: 122 loss: tensor(0.2089)\n",
      "epoch: 123 loss: tensor(0.2083)\n",
      "epoch: 124 loss: tensor(0.2079)\n",
      "epoch: 125 loss: tensor(0.2081)\n",
      "epoch: 126 loss: tensor(0.2080)\n",
      "epoch: 127 loss: tensor(0.2072)\n",
      "epoch: 128 loss: tensor(0.2064)\n",
      "epoch: 129 loss: tensor(0.2060)\n",
      "epoch: 130 loss: tensor(0.2061)\n",
      "epoch: 131 loss: tensor(0.2061)\n",
      "epoch: 132 loss: tensor(0.2057)\n",
      "epoch: 133 loss: tensor(0.2051)\n",
      "epoch: 134 loss: tensor(0.2044)\n",
      "epoch: 135 loss: tensor(0.2041)\n",
      "epoch: 136 loss: tensor(0.2041)\n",
      "epoch: 137 loss: tensor(0.2041)\n",
      "epoch: 138 loss: tensor(0.2036)\n",
      "epoch: 139 loss: tensor(0.2029)\n",
      "epoch: 140 loss: tensor(0.2024)\n",
      "epoch: 141 loss: tensor(0.2023)\n",
      "epoch: 142 loss: tensor(0.2025)\n",
      "epoch: 143 loss: tensor(0.2024)\n",
      "epoch: 144 loss: tensor(0.2017)\n",
      "epoch: 145 loss: tensor(0.2011)\n",
      "epoch: 146 loss: tensor(0.2006)\n",
      "epoch: 147 loss: tensor(0.2007)\n",
      "epoch: 148 loss: tensor(0.2013)\n",
      "epoch: 149 loss: tensor(0.2010)\n",
      "epoch: 150 loss: tensor(0.2000)\n",
      "epoch: 151 loss: tensor(0.1994)\n",
      "epoch: 152 loss: tensor(0.1994)\n",
      "epoch: 153 loss: tensor(0.2002)\n",
      "epoch: 154 loss: tensor(0.2001)\n",
      "epoch: 155 loss: tensor(0.1991)\n",
      "epoch: 156 loss: tensor(0.1984)\n",
      "epoch: 157 loss: tensor(0.1982)\n",
      "epoch: 158 loss: tensor(0.1988)\n",
      "epoch: 159 loss: tensor(0.1996)\n",
      "epoch: 160 loss: tensor(0.1987)\n",
      "epoch: 161 loss: tensor(0.1975)\n",
      "epoch: 162 loss: tensor(0.1970)\n",
      "epoch: 163 loss: tensor(0.1970)\n",
      "epoch: 164 loss: tensor(0.1987)\n",
      "epoch: 165 loss: tensor(0.1993)\n",
      "epoch: 166 loss: tensor(0.1971)\n",
      "epoch: 167 loss: tensor(0.1962)\n",
      "epoch: 168 loss: tensor(0.1958)\n",
      "epoch: 169 loss: tensor(0.1955)\n",
      "epoch: 170 loss: tensor(0.1953)\n",
      "epoch: 171 loss: tensor(0.1990)\n",
      "epoch: 172 loss: tensor(0.2005)\n",
      "epoch: 173 loss: tensor(0.1958)\n",
      "epoch: 174 loss: tensor(0.1954)\n",
      "epoch: 175 loss: tensor(0.1957)\n",
      "epoch: 176 loss: tensor(0.1980)\n",
      "epoch: 177 loss: tensor(0.2000)\n",
      "epoch: 178 loss: tensor(0.1958)\n",
      "epoch: 179 loss: tensor(0.1946)\n",
      "epoch: 180 loss: tensor(0.1945)\n",
      "epoch: 181 loss: tensor(0.1946)\n",
      "epoch: 182 loss: tensor(0.1962)\n",
      "epoch: 183 loss: tensor(0.1991)\n",
      "epoch: 184 loss: tensor(0.1950)\n",
      "epoch: 185 loss: tensor(0.1936)\n",
      "epoch: 186 loss: tensor(0.1938)\n",
      "epoch: 187 loss: tensor(0.1939)\n",
      "epoch: 188 loss: tensor(0.1946)\n",
      "epoch: 189 loss: tensor(0.2014)\n",
      "epoch: 190 loss: tensor(0.1976)\n",
      "epoch: 191 loss: tensor(0.1942)\n",
      "epoch: 192 loss: tensor(0.1936)\n",
      "epoch: 193 loss: tensor(0.1934)\n",
      "epoch: 194 loss: tensor(0.1933)\n",
      "epoch: 195 loss: tensor(0.1946)\n",
      "epoch: 196 loss: tensor(0.2015)\n",
      "epoch: 197 loss: tensor(0.1955)\n",
      "epoch: 198 loss: tensor(0.1935)\n",
      "epoch: 199 loss: tensor(0.1933)\n",
      "epoch: 200 loss: tensor(0.1935)\n",
      "test loss: tensor(0.3132)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200 #200\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_player in range(nb_player):\n",
    "        input = Variable(training_set_1[id_player]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        #Select only rating related columns to compute loss\n",
    "        target_ratings = target[:, :nb_stats]\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            output_ratings = output[:, :nb_stats]\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output_ratings, target_ratings)\n",
    "            mean_corrector = nb_stats/float(torch.sum(target.data > 0) + 1e-10)\n",
    "#             print(mean_corrector)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "    \n",
    "# Testing the SAE\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_player in range(len(test_set_1)):\n",
    "    input = Variable(test_set_1[id_player]).unsqueeze(0)\n",
    "    target = Variable(test_set_1[id_player]).unsqueeze(0)\n",
    "    target_ratings = target[:, :nb_stats]\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        output_ratings = output[:, :nb_stats]\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output_ratings, target_ratings)\n",
    "        mean_corrector = nb_stats/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1132, -0.3299, -0.1745, -0.1161, -0.2307, -0.0153,  0.0016,  0.0619,\n",
       "          -0.1594, -0.1892, -0.2939, -0.2778, -0.0546,  0.1120, -0.2290, -0.1972,\n",
       "           0.2376,  0.2115,  0.2775,  0.2647, -0.3885, -0.2582, -0.2341,  0.0351,\n",
       "          -0.1593, -0.1808,  0.2824,  0.0758, -0.0422],\n",
       "         [-0.1129, -0.3292, -0.1738, -0.1156, -0.2301, -0.0159,  0.0016,  0.0617,\n",
       "          -0.1592, -0.1890, -0.2933, -0.2773, -0.0548,  0.1109, -0.2286, -0.1970,\n",
       "           0.2362,  0.2103,  0.2760,  0.2632, -0.3875, -0.2577, -0.2339,  0.0347,\n",
       "          -0.1591, -0.1804,  0.2815,  0.0752, -0.0425],\n",
       "         [-0.1131, -0.3297, -0.1742, -0.1158, -0.2303, -0.0156,  0.0016,  0.0619,\n",
       "          -0.1592, -0.1891, -0.2937, -0.2779, -0.0546,  0.1113, -0.2289, -0.1972,\n",
       "           0.2371,  0.2109,  0.2770,  0.2640, -0.3883, -0.2582, -0.2343,  0.0350,\n",
       "          -0.1594, -0.1808,  0.2825,  0.0753, -0.0426],\n",
       "         [-0.1129, -0.3292, -0.1737, -0.1154, -0.2298, -0.0162,  0.0016,  0.0617,\n",
       "          -0.1592, -0.1890, -0.2932, -0.2774, -0.0549,  0.1104, -0.2286, -0.1970,\n",
       "           0.2358,  0.2099,  0.2756,  0.2629, -0.3874, -0.2577, -0.2340,  0.0346,\n",
       "          -0.1592, -0.1804,  0.2817,  0.0748, -0.0429],\n",
       "         [-0.1130, -0.3293, -0.1738, -0.1157, -0.2302, -0.0156,  0.0016,  0.0618,\n",
       "          -0.1592, -0.1890, -0.2934, -0.2774, -0.0547,  0.1112, -0.2287, -0.1970,\n",
       "           0.2366,  0.2105,  0.2764,  0.2635, -0.3877, -0.2579, -0.2339,  0.0348,\n",
       "          -0.1592, -0.1806,  0.2817,  0.0754, -0.0422],\n",
       "         [-0.1131, -0.3296, -0.1741, -0.1157, -0.2302, -0.0159,  0.0016,  0.0618,\n",
       "          -0.1593, -0.1891, -0.2936, -0.2777, -0.0548,  0.1110, -0.2288, -0.1972,\n",
       "           0.2367,  0.2107,  0.2765,  0.2638, -0.3880, -0.2580, -0.2342,  0.0348,\n",
       "          -0.1593, -0.1806,  0.2822,  0.0752, -0.0427],\n",
       "         [-0.1130, -0.3291, -0.1738, -0.1158, -0.2303, -0.0153,  0.0016,  0.0618,\n",
       "          -0.1590, -0.1888, -0.2933, -0.2775, -0.0545,  0.1115, -0.2287, -0.1969,\n",
       "           0.2368,  0.2105,  0.2767,  0.2635, -0.3878, -0.2581, -0.2339,  0.0350,\n",
       "          -0.1592, -0.1808,  0.2817,  0.0756, -0.0419],\n",
       "         [-0.1128, -0.3288, -0.1734, -0.1154, -0.2298, -0.0159,  0.0016,  0.0616,\n",
       "          -0.1590, -0.1887, -0.2929, -0.2771, -0.0547,  0.1106, -0.2285, -0.1968,\n",
       "           0.2357,  0.2097,  0.2755,  0.2626, -0.3871, -0.2577, -0.2338,  0.0347,\n",
       "          -0.1591, -0.1804,  0.2812,  0.0750, -0.0424],\n",
       "         [-0.1132, -0.3299, -0.1746, -0.1161, -0.2307, -0.0152,  0.0016,  0.0620,\n",
       "          -0.1593, -0.1891, -0.2939, -0.2781, -0.0545,  0.1120, -0.2291, -0.1973,\n",
       "           0.2379,  0.2116,  0.2778,  0.2648, -0.3887, -0.2584, -0.2343,  0.0352,\n",
       "          -0.1595, -0.1810,  0.2829,  0.0758, -0.0422],\n",
       "         [-0.1131, -0.3298, -0.1743, -0.1159, -0.2305, -0.0154,  0.0016,  0.0619,\n",
       "          -0.1592, -0.1891, -0.2938, -0.2779, -0.0545,  0.1116, -0.2290, -0.1972,\n",
       "           0.2374,  0.2112,  0.2773,  0.2643, -0.3885, -0.2583, -0.2343,  0.0351,\n",
       "          -0.1594, -0.1809,  0.2826,  0.0756, -0.0424],\n",
       "         [-0.1130, -0.3293, -0.1739, -0.1157, -0.2301, -0.0157,  0.0016,  0.0618,\n",
       "          -0.1591, -0.1889, -0.2934, -0.2776, -0.0547,  0.1111, -0.2287, -0.1970,\n",
       "           0.2365,  0.2104,  0.2764,  0.2634, -0.3878, -0.2580, -0.2340,  0.0349,\n",
       "          -0.1593, -0.1807,  0.2819,  0.0752, -0.0424],\n",
       "         [-0.1126, -0.3283, -0.1729, -0.1151, -0.2294, -0.0162,  0.0016,  0.0615,\n",
       "          -0.1589, -0.1886, -0.2925, -0.2767, -0.0549,  0.1100, -0.2282, -0.1966,\n",
       "           0.2348,  0.2089,  0.2745,  0.2616, -0.3864, -0.2573, -0.2335,  0.0344,\n",
       "          -0.1589, -0.1801,  0.2803,  0.0747, -0.0424],\n",
       "         [-0.1129, -0.3290, -0.1737, -0.1157, -0.2302, -0.0155,  0.0016,  0.0617,\n",
       "          -0.1590, -0.1888, -0.2932, -0.2773, -0.0546,  0.1113, -0.2286, -0.1969,\n",
       "           0.2365,  0.2103,  0.2763,  0.2633, -0.3876, -0.2579, -0.2338,  0.0348,\n",
       "          -0.1591, -0.1806,  0.2815,  0.0755, -0.0420],\n",
       "         [-0.1132, -0.3300, -0.1745, -0.1159, -0.2305, -0.0158,  0.0016,  0.0620,\n",
       "          -0.1595, -0.1893, -0.2939, -0.2779, -0.0548,  0.1115, -0.2290, -0.1973,\n",
       "           0.2374,  0.2114,  0.2772,  0.2645, -0.3885, -0.2581, -0.2343,  0.0349,\n",
       "          -0.1593, -0.1806,  0.2828,  0.0754, -0.0428],\n",
       "         [-0.1130, -0.3293, -0.1740, -0.1159, -0.2304, -0.0153,  0.0016,  0.0618,\n",
       "          -0.1591, -0.1889, -0.2935, -0.2776, -0.0545,  0.1117, -0.2288, -0.1970,\n",
       "           0.2371,  0.2109,  0.2770,  0.2639, -0.3881, -0.2581, -0.2340,  0.0350,\n",
       "          -0.1593, -0.1808,  0.2820,  0.0757, -0.0419]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0393, -0.0398, -0.0394, -0.0399, -0.0397, -0.0396, -0.0395, -0.0399,\n",
       "         -0.0391, -0.0393, -0.0396, -0.0403, -0.0397, -0.0394, -0.0394],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.3294, 0.3277, 0.3292, 0.3275, 0.3276, 0.3286, 0.3281, 0.3269, 0.3303,\n",
       "          0.3295, 0.3283, 0.3253, 0.3274, 0.3298, 0.3285],\n",
       "         [0.3329, 0.3307, 0.3326, 0.3312, 0.3319, 0.3322, 0.3310, 0.3299, 0.3325,\n",
       "          0.3327, 0.3312, 0.3290, 0.3310, 0.3328, 0.3317],\n",
       "         [0.3274, 0.3265, 0.3274, 0.3257, 0.3254, 0.3268, 0.3270, 0.3255, 0.3296,\n",
       "          0.3280, 0.3269, 0.3234, 0.3257, 0.3285, 0.3271],\n",
       "         [0.3328, 0.3305, 0.3324, 0.3308, 0.3312, 0.3318, 0.3307, 0.3298, 0.3326,\n",
       "          0.3324, 0.3312, 0.3286, 0.3306, 0.3327, 0.3314],\n",
       "         [0.3338, 0.3316, 0.3335, 0.3320, 0.3327, 0.3330, 0.3319, 0.3308, 0.3335,\n",
       "          0.3336, 0.3321, 0.3299, 0.3318, 0.3337, 0.3326]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.7602, -0.7798, -0.7512, -0.7781, -0.7848], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.5456, -0.5568, -0.5403, -0.5549, -0.5594],\n",
       "         [-0.5448, -0.5559, -0.5389, -0.5547, -0.5595],\n",
       "         [-0.5417, -0.5561, -0.5362, -0.5549, -0.5586],\n",
       "         [-0.5449, -0.5552, -0.5388, -0.5542, -0.5598],\n",
       "         [-0.5454, -0.5549, -0.5392, -0.5539, -0.5595],\n",
       "         [-0.5449, -0.5543, -0.5388, -0.5531, -0.5584],\n",
       "         [-0.5396, -0.5575, -0.5339, -0.5572, -0.5602],\n",
       "         [-0.5433, -0.5565, -0.5376, -0.5555, -0.5597],\n",
       "         [-0.5452, -0.5569, -0.5390, -0.5565, -0.5613],\n",
       "         [-0.5425, -0.5577, -0.5370, -0.5566, -0.5601],\n",
       "         [-0.5460, -0.5560, -0.5400, -0.5550, -0.5603],\n",
       "         [-0.5404, -0.5568, -0.5345, -0.5564, -0.5598],\n",
       "         [-0.5422, -0.5574, -0.5364, -0.5563, -0.5597],\n",
       "         [-0.5434, -0.5557, -0.5376, -0.5547, -0.5592],\n",
       "         [-0.5465, -0.5563, -0.5407, -0.5548, -0.5601]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4455, -0.4650, -0.4672, -0.4654, -0.4481, -0.4563, -0.4651, -0.4623,\n",
       "         -0.4532, -0.4613, -0.4661, -0.4844, -0.4420, -0.4469, -0.4865],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.2065e-01,  1.1312e-01,  1.2292e-01,  1.1358e-01,  1.2696e-01,\n",
       "           1.2574e-01,  1.2428e-01,  1.1612e-01,  1.1410e-01,  1.1761e-01,\n",
       "           1.0534e-01,  1.0998e-01,  1.4172e-01,  1.3251e-01,  9.1807e-02],\n",
       "         [ 3.4006e-01,  3.1934e-01,  3.3848e-01,  3.2096e-01,  3.4968e-01,\n",
       "           3.4749e-01,  3.4108e-01,  3.2829e-01,  3.2341e-01,  3.2709e-01,\n",
       "           3.0508e-01,  3.0994e-01,  3.8081e-01,  3.6075e-01,  2.7272e-01],\n",
       "         [ 6.6008e-02,  4.7002e-02,  5.9677e-02,  4.8071e-02,  6.6709e-02,\n",
       "           6.5385e-02,  6.2142e-02,  5.5927e-02,  4.9094e-02,  5.2606e-02,\n",
       "           3.9771e-02,  4.0942e-02,  6.8947e-02,  7.0855e-02,  1.5163e-02],\n",
       "         [ 1.9125e-01,  1.7898e-01,  1.8994e-01,  1.8402e-01,  1.8894e-01,\n",
       "           1.8854e-01,  1.9249e-01,  1.8853e-01,  1.7865e-01,  1.8670e-01,\n",
       "           1.7804e-01,  1.8103e-01,  1.9636e-01,  1.9445e-01,  1.7038e-01],\n",
       "         [ 1.9357e-01,  1.7155e-01,  1.8167e-01,  1.6928e-01,  1.9630e-01,\n",
       "           1.9334e-01,  1.8497e-01,  1.7827e-01,  1.7679e-01,  1.7333e-01,\n",
       "           1.6033e-01,  1.5809e-01,  2.0858e-01,  2.0109e-01,  1.2679e-01],\n",
       "         [ 5.4968e-02,  5.1587e-02,  6.2854e-02,  5.6617e-02,  6.1994e-02,\n",
       "           6.5128e-02,  6.1807e-02,  5.8180e-02,  5.0493e-02,  5.2775e-02,\n",
       "           4.6064e-02,  5.4498e-02,  8.6029e-02,  7.0192e-02,  3.7163e-02],\n",
       "         [ 1.3793e-02,  1.3628e-02,  1.3427e-02,  1.3786e-02,  3.8463e-03,\n",
       "           3.9076e-03,  3.1763e-03,  1.3666e-02,  1.3760e-02,  1.3271e-02,\n",
       "           1.3741e-02,  1.3226e-02,  1.3633e-02,  1.3717e-02,  1.3469e-02],\n",
       "         [ 3.5258e-02,  3.4714e-02,  3.4110e-02,  3.5319e-02,  3.5392e-02,\n",
       "           3.5712e-02,  3.3188e-02,  3.4910e-02,  3.5151e-02,  3.3472e-02,\n",
       "           3.5148e-02,  3.3447e-02,  3.4787e-02,  3.4984e-02,  3.4255e-02],\n",
       "         [ 1.0427e-01,  8.8123e-02,  1.0225e-01,  9.0680e-02,  1.0926e-01,\n",
       "           1.0942e-01,  1.0395e-01,  9.7182e-02,  8.9764e-02,  9.0852e-02,\n",
       "           7.8625e-02,  8.3251e-02,  1.2975e-01,  1.1755e-01,  5.3994e-02],\n",
       "         [ 1.4347e-01,  1.2895e-01,  1.4247e-01,  1.3166e-01,  1.4996e-01,\n",
       "           1.5073e-01,  1.4259e-01,  1.3680e-01,  1.3145e-01,  1.3158e-01,\n",
       "           1.2018e-01,  1.2303e-01,  1.6997e-01,  1.5742e-01,  9.6682e-02],\n",
       "         [ 3.0857e-01,  2.9081e-01,  3.0535e-01,  2.9241e-01,  3.1548e-01,\n",
       "           3.1425e-01,  3.0708e-01,  2.9877e-01,  2.9462e-01,  2.9524e-01,\n",
       "           2.7964e-01,  2.8198e-01,  3.3880e-01,  3.2375e-01,  2.5171e-01],\n",
       "         [ 3.7517e-01,  3.6695e-01,  3.6954e-01,  3.7093e-01,  3.7217e-01,\n",
       "           3.7175e-01,  3.7089e-01,  3.7274e-01,  3.6844e-01,  3.6898e-01,\n",
       "           3.6870e-01,  3.6521e-01,  3.8465e-01,  3.7522e-01,  3.6663e-01],\n",
       "         [-5.9414e-02, -6.1334e-02, -5.2881e-02, -5.5687e-02, -5.5834e-02,\n",
       "          -5.1399e-02, -5.4428e-02, -5.4711e-02, -6.4017e-02, -6.2448e-02,\n",
       "          -6.3915e-02, -5.7111e-02, -4.4315e-02, -5.0772e-02, -6.8659e-02],\n",
       "         [-8.3846e-02, -7.6716e-02, -7.0334e-02, -7.0872e-02, -7.6203e-02,\n",
       "          -7.0788e-02, -7.4098e-02, -7.3983e-02, -8.0416e-02, -7.9047e-02,\n",
       "          -7.8508e-02, -6.9405e-02, -5.8389e-02, -7.1016e-02, -7.4382e-02],\n",
       "         [ 2.8037e-01,  2.7004e-01,  2.7975e-01,  2.7343e-01,  2.8403e-01,\n",
       "           2.8377e-01,  2.8062e-01,  2.7618e-01,  2.7193e-01,  2.7466e-01,\n",
       "           2.6532e-01,  2.6682e-01,  3.0311e-01,  2.9014e-01,  2.5342e-01],\n",
       "         [ 2.7461e-01,  2.6310e-01,  2.7429e-01,  2.6578e-01,  2.7962e-01,\n",
       "           2.7813e-01,  2.7575e-01,  2.6861e-01,  2.6521e-01,  2.6954e-01,\n",
       "           2.5685e-01,  2.5914e-01,  3.0137e-01,  2.8672e-01,  2.4328e-01],\n",
       "         [-3.4487e-01, -3.3179e-01, -3.2593e-01, -3.2245e-01, -3.4147e-01,\n",
       "          -3.3238e-01, -3.2949e-01, -3.2644e-01, -3.4106e-01, -3.3581e-01,\n",
       "          -3.2928e-01, -3.1487e-01, -3.3329e-01, -3.3751e-01, -3.1268e-01],\n",
       "         [-1.7651e-01, -1.6847e-01, -1.7055e-01, -1.6493e-01, -1.7627e-01,\n",
       "          -1.7144e-01, -1.7381e-01, -1.6780e-01, -1.7119e-01, -1.7311e-01,\n",
       "          -1.6464e-01, -1.6210e-01, -1.7345e-01, -1.7655e-01, -1.5453e-01],\n",
       "         [-4.0921e-01, -3.9591e-01, -3.8498e-01, -3.8790e-01, -4.0003e-01,\n",
       "          -3.9113e-01, -3.8833e-01, -3.9148e-01, -4.0558e-01, -3.9790e-01,\n",
       "          -3.9914e-01, -3.7958e-01, -3.8674e-01, -3.9390e-01, -3.8866e-01],\n",
       "         [-2.2784e-01, -2.1964e-01, -2.2475e-01, -2.1564e-01, -2.3125e-01,\n",
       "          -2.2592e-01, -2.2785e-01, -2.1828e-01, -2.2267e-01, -2.2627e-01,\n",
       "          -2.1288e-01, -2.1223e-01, -2.3178e-01, -2.3272e-01, -1.9953e-01],\n",
       "         [ 4.3211e-01,  4.2239e-01,  4.2523e-01,  4.2358e-01,  4.3444e-01,\n",
       "           4.3447e-01,  4.2504e-01,  4.2633e-01,  4.2685e-01,  4.2037e-01,\n",
       "           4.1793e-01,  4.1336e-01,  4.4724e-01,  4.3694e-01,  4.0222e-01],\n",
       "         [ 2.8851e-01,  2.8813e-01,  2.9798e-01,  2.9165e-01,  2.9762e-01,\n",
       "           3.0068e-01,  2.9612e-01,  2.9126e-01,  2.8858e-01,  2.9144e-01,\n",
       "           2.8147e-01,  2.8708e-01,  3.1193e-01,  3.0196e-01,  2.7353e-01],\n",
       "         [ 2.7254e-01,  2.7445e-01,  2.8079e-01,  2.8103e-01,  2.7757e-01,\n",
       "           2.8206e-01,  2.7851e-01,  2.7975e-01,  2.7276e-01,  2.7283e-01,\n",
       "           2.7282e-01,  2.7799e-01,  2.9400e-01,  2.8238e-01,  2.7273e-01],\n",
       "         [ 6.3088e-03,  3.0559e-04,  5.0097e-03,  3.4124e-04,  1.0322e-02,\n",
       "           1.1826e-02,  3.4089e-03,  3.1819e-03,  1.8374e-03, -2.2256e-03,\n",
       "          -4.8192e-03, -4.7689e-03,  1.3763e-02,  1.1392e-02, -1.9603e-02],\n",
       "         [ 2.7356e-01,  2.6448e-01,  2.6514e-01,  2.6684e-01,  2.6883e-01,\n",
       "           2.6777e-01,  2.6681e-01,  2.6974e-01,  2.6646e-01,  2.6564e-01,\n",
       "           2.6695e-01,  2.6229e-01,  2.7865e-01,  2.7101e-01,  2.6373e-01],\n",
       "         [ 2.1126e-01,  2.0226e-01,  2.0060e-01,  2.0508e-01,  2.0246e-01,\n",
       "           2.0210e-01,  2.0236e-01,  2.0804e-01,  2.0417e-01,  2.0377e-01,\n",
       "           2.0774e-01,  2.0071e-01,  2.0174e-01,  2.0203e-01,  2.0807e-01],\n",
       "         [ 1.3302e-01,  1.1775e-01,  1.2245e-01,  1.2208e-01,  1.2988e-01,\n",
       "           1.3064e-01,  1.2126e-01,  1.2677e-01,  1.2028e-01,  1.1510e-01,\n",
       "           1.1872e-01,  1.1281e-01,  1.3794e-01,  1.3267e-01,  1.0366e-01],\n",
       "         [-4.2814e-02, -4.2169e-02, -4.2055e-02, -4.0566e-02, -4.1517e-02,\n",
       "          -3.9582e-02, -4.3571e-02, -4.0791e-02, -4.2512e-02, -4.6165e-02,\n",
       "          -4.2238e-02, -4.1613e-02, -3.3716e-02, -4.0022e-02, -4.3320e-02],\n",
       "         [-1.4242e-01, -1.3516e-01, -1.3267e-01, -1.2701e-01, -1.4229e-01,\n",
       "          -1.3595e-01, -1.3741e-01, -1.3016e-01, -1.3966e-01, -1.3809e-01,\n",
       "          -1.2895e-01, -1.2444e-01, -1.3888e-01, -1.4033e-01, -1.1681e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0414,  0.2351,  0.5165,  0.2345,  0.3098,  0.5465,  0.0223,  0.1117,\n",
       "          0.5899,  0.5577,  0.1856, -0.2199,  0.7287,  0.6822,  0.0884,  0.0850,\n",
       "          1.1501,  0.7075,  1.2428,  0.8255, -0.3346, -0.0400, -0.0535,  0.5407,\n",
       "         -0.0914,  0.0392,  0.8356,  0.3832,  0.7580], requires_grad=True)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = list(sae.parameters())\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight tensor([[-0.1132, -0.3299, -0.1745, -0.1161, -0.2307, -0.0153,  0.0016,  0.0619,\n",
      "         -0.1594, -0.1892, -0.2939, -0.2778, -0.0546,  0.1120, -0.2290, -0.1972,\n",
      "          0.2376,  0.2115,  0.2775,  0.2647, -0.3885, -0.2582, -0.2341,  0.0351,\n",
      "         -0.1593, -0.1808,  0.2824,  0.0758, -0.0422],\n",
      "        [-0.1129, -0.3292, -0.1738, -0.1156, -0.2301, -0.0159,  0.0016,  0.0617,\n",
      "         -0.1592, -0.1890, -0.2933, -0.2773, -0.0548,  0.1109, -0.2286, -0.1970,\n",
      "          0.2362,  0.2103,  0.2760,  0.2632, -0.3875, -0.2577, -0.2339,  0.0347,\n",
      "         -0.1591, -0.1804,  0.2815,  0.0752, -0.0425],\n",
      "        [-0.1131, -0.3297, -0.1742, -0.1158, -0.2303, -0.0156,  0.0016,  0.0619,\n",
      "         -0.1592, -0.1891, -0.2937, -0.2779, -0.0546,  0.1113, -0.2289, -0.1972,\n",
      "          0.2371,  0.2109,  0.2770,  0.2640, -0.3883, -0.2582, -0.2343,  0.0350,\n",
      "         -0.1594, -0.1808,  0.2825,  0.0753, -0.0426],\n",
      "        [-0.1129, -0.3292, -0.1737, -0.1154, -0.2298, -0.0162,  0.0016,  0.0617,\n",
      "         -0.1592, -0.1890, -0.2932, -0.2774, -0.0549,  0.1104, -0.2286, -0.1970,\n",
      "          0.2358,  0.2099,  0.2756,  0.2629, -0.3874, -0.2577, -0.2340,  0.0346,\n",
      "         -0.1592, -0.1804,  0.2817,  0.0748, -0.0429],\n",
      "        [-0.1130, -0.3293, -0.1738, -0.1157, -0.2302, -0.0156,  0.0016,  0.0618,\n",
      "         -0.1592, -0.1890, -0.2934, -0.2774, -0.0547,  0.1112, -0.2287, -0.1970,\n",
      "          0.2366,  0.2105,  0.2764,  0.2635, -0.3877, -0.2579, -0.2339,  0.0348,\n",
      "         -0.1592, -0.1806,  0.2817,  0.0754, -0.0422],\n",
      "        [-0.1131, -0.3296, -0.1741, -0.1157, -0.2302, -0.0159,  0.0016,  0.0618,\n",
      "         -0.1593, -0.1891, -0.2936, -0.2777, -0.0548,  0.1110, -0.2288, -0.1972,\n",
      "          0.2367,  0.2107,  0.2765,  0.2638, -0.3880, -0.2580, -0.2342,  0.0348,\n",
      "         -0.1593, -0.1806,  0.2822,  0.0752, -0.0427],\n",
      "        [-0.1130, -0.3291, -0.1738, -0.1158, -0.2303, -0.0153,  0.0016,  0.0618,\n",
      "         -0.1590, -0.1888, -0.2933, -0.2775, -0.0545,  0.1115, -0.2287, -0.1969,\n",
      "          0.2368,  0.2105,  0.2767,  0.2635, -0.3878, -0.2581, -0.2339,  0.0350,\n",
      "         -0.1592, -0.1808,  0.2817,  0.0756, -0.0419],\n",
      "        [-0.1128, -0.3288, -0.1734, -0.1154, -0.2298, -0.0159,  0.0016,  0.0616,\n",
      "         -0.1590, -0.1887, -0.2929, -0.2771, -0.0547,  0.1106, -0.2285, -0.1968,\n",
      "          0.2357,  0.2097,  0.2755,  0.2626, -0.3871, -0.2577, -0.2338,  0.0347,\n",
      "         -0.1591, -0.1804,  0.2812,  0.0750, -0.0424],\n",
      "        [-0.1132, -0.3299, -0.1746, -0.1161, -0.2307, -0.0152,  0.0016,  0.0620,\n",
      "         -0.1593, -0.1891, -0.2939, -0.2781, -0.0545,  0.1120, -0.2291, -0.1973,\n",
      "          0.2379,  0.2116,  0.2778,  0.2648, -0.3887, -0.2584, -0.2343,  0.0352,\n",
      "         -0.1595, -0.1810,  0.2829,  0.0758, -0.0422],\n",
      "        [-0.1131, -0.3298, -0.1743, -0.1159, -0.2305, -0.0154,  0.0016,  0.0619,\n",
      "         -0.1592, -0.1891, -0.2938, -0.2779, -0.0545,  0.1116, -0.2290, -0.1972,\n",
      "          0.2374,  0.2112,  0.2773,  0.2643, -0.3885, -0.2583, -0.2343,  0.0351,\n",
      "         -0.1594, -0.1809,  0.2826,  0.0756, -0.0424],\n",
      "        [-0.1130, -0.3293, -0.1739, -0.1157, -0.2301, -0.0157,  0.0016,  0.0618,\n",
      "         -0.1591, -0.1889, -0.2934, -0.2776, -0.0547,  0.1111, -0.2287, -0.1970,\n",
      "          0.2365,  0.2104,  0.2764,  0.2634, -0.3878, -0.2580, -0.2340,  0.0349,\n",
      "         -0.1593, -0.1807,  0.2819,  0.0752, -0.0424],\n",
      "        [-0.1126, -0.3283, -0.1729, -0.1151, -0.2294, -0.0162,  0.0016,  0.0615,\n",
      "         -0.1589, -0.1886, -0.2925, -0.2767, -0.0549,  0.1100, -0.2282, -0.1966,\n",
      "          0.2348,  0.2089,  0.2745,  0.2616, -0.3864, -0.2573, -0.2335,  0.0344,\n",
      "         -0.1589, -0.1801,  0.2803,  0.0747, -0.0424],\n",
      "        [-0.1129, -0.3290, -0.1737, -0.1157, -0.2302, -0.0155,  0.0016,  0.0617,\n",
      "         -0.1590, -0.1888, -0.2932, -0.2773, -0.0546,  0.1113, -0.2286, -0.1969,\n",
      "          0.2365,  0.2103,  0.2763,  0.2633, -0.3876, -0.2579, -0.2338,  0.0348,\n",
      "         -0.1591, -0.1806,  0.2815,  0.0755, -0.0420],\n",
      "        [-0.1132, -0.3300, -0.1745, -0.1159, -0.2305, -0.0158,  0.0016,  0.0620,\n",
      "         -0.1595, -0.1893, -0.2939, -0.2779, -0.0548,  0.1115, -0.2290, -0.1973,\n",
      "          0.2374,  0.2114,  0.2772,  0.2645, -0.3885, -0.2581, -0.2343,  0.0349,\n",
      "         -0.1593, -0.1806,  0.2828,  0.0754, -0.0428],\n",
      "        [-0.1130, -0.3293, -0.1740, -0.1159, -0.2304, -0.0153,  0.0016,  0.0618,\n",
      "         -0.1591, -0.1889, -0.2935, -0.2776, -0.0545,  0.1117, -0.2288, -0.1970,\n",
      "          0.2371,  0.2109,  0.2770,  0.2639, -0.3881, -0.2581, -0.2340,  0.0350,\n",
      "         -0.1593, -0.1808,  0.2820,  0.0757, -0.0419]])\n",
      "fc1.bias tensor([-0.0393, -0.0398, -0.0394, -0.0399, -0.0397, -0.0396, -0.0395, -0.0399,\n",
      "        -0.0391, -0.0393, -0.0396, -0.0403, -0.0397, -0.0394, -0.0394])\n",
      "fc2.weight tensor([[0.3294, 0.3277, 0.3292, 0.3275, 0.3276, 0.3286, 0.3281, 0.3269, 0.3303,\n",
      "         0.3295, 0.3283, 0.3253, 0.3274, 0.3298, 0.3285],\n",
      "        [0.3329, 0.3307, 0.3326, 0.3312, 0.3319, 0.3322, 0.3310, 0.3299, 0.3325,\n",
      "         0.3327, 0.3312, 0.3290, 0.3310, 0.3328, 0.3317],\n",
      "        [0.3274, 0.3265, 0.3274, 0.3257, 0.3254, 0.3268, 0.3270, 0.3255, 0.3296,\n",
      "         0.3280, 0.3269, 0.3234, 0.3257, 0.3285, 0.3271],\n",
      "        [0.3328, 0.3305, 0.3324, 0.3308, 0.3312, 0.3318, 0.3307, 0.3298, 0.3326,\n",
      "         0.3324, 0.3312, 0.3286, 0.3306, 0.3327, 0.3314],\n",
      "        [0.3338, 0.3316, 0.3335, 0.3320, 0.3327, 0.3330, 0.3319, 0.3308, 0.3335,\n",
      "         0.3336, 0.3321, 0.3299, 0.3318, 0.3337, 0.3326]])\n",
      "fc2.bias tensor([-0.7602, -0.7798, -0.7512, -0.7781, -0.7848])\n",
      "fc3.weight tensor([[-0.5456, -0.5568, -0.5403, -0.5549, -0.5594],\n",
      "        [-0.5448, -0.5559, -0.5389, -0.5547, -0.5595],\n",
      "        [-0.5417, -0.5561, -0.5362, -0.5549, -0.5586],\n",
      "        [-0.5449, -0.5552, -0.5388, -0.5542, -0.5598],\n",
      "        [-0.5454, -0.5549, -0.5392, -0.5539, -0.5595],\n",
      "        [-0.5449, -0.5543, -0.5388, -0.5531, -0.5584],\n",
      "        [-0.5396, -0.5575, -0.5339, -0.5572, -0.5602],\n",
      "        [-0.5433, -0.5565, -0.5376, -0.5555, -0.5597],\n",
      "        [-0.5452, -0.5569, -0.5390, -0.5565, -0.5613],\n",
      "        [-0.5425, -0.5577, -0.5370, -0.5566, -0.5601],\n",
      "        [-0.5460, -0.5560, -0.5400, -0.5550, -0.5603],\n",
      "        [-0.5404, -0.5568, -0.5345, -0.5564, -0.5598],\n",
      "        [-0.5422, -0.5574, -0.5364, -0.5563, -0.5597],\n",
      "        [-0.5434, -0.5557, -0.5376, -0.5547, -0.5592],\n",
      "        [-0.5465, -0.5563, -0.5407, -0.5548, -0.5601]])\n",
      "fc3.bias tensor([-0.4455, -0.4650, -0.4672, -0.4654, -0.4481, -0.4563, -0.4651, -0.4623,\n",
      "        -0.4532, -0.4613, -0.4661, -0.4844, -0.4420, -0.4469, -0.4865])\n",
      "fc4.weight tensor([[ 1.2065e-01,  1.1312e-01,  1.2292e-01,  1.1358e-01,  1.2696e-01,\n",
      "          1.2574e-01,  1.2428e-01,  1.1612e-01,  1.1410e-01,  1.1761e-01,\n",
      "          1.0534e-01,  1.0998e-01,  1.4172e-01,  1.3251e-01,  9.1807e-02],\n",
      "        [ 3.4006e-01,  3.1934e-01,  3.3848e-01,  3.2096e-01,  3.4968e-01,\n",
      "          3.4749e-01,  3.4108e-01,  3.2829e-01,  3.2341e-01,  3.2709e-01,\n",
      "          3.0508e-01,  3.0994e-01,  3.8081e-01,  3.6075e-01,  2.7272e-01],\n",
      "        [ 6.6008e-02,  4.7002e-02,  5.9677e-02,  4.8071e-02,  6.6709e-02,\n",
      "          6.5385e-02,  6.2142e-02,  5.5927e-02,  4.9094e-02,  5.2606e-02,\n",
      "          3.9771e-02,  4.0942e-02,  6.8947e-02,  7.0855e-02,  1.5163e-02],\n",
      "        [ 1.9125e-01,  1.7898e-01,  1.8994e-01,  1.8402e-01,  1.8894e-01,\n",
      "          1.8854e-01,  1.9249e-01,  1.8853e-01,  1.7865e-01,  1.8670e-01,\n",
      "          1.7804e-01,  1.8103e-01,  1.9636e-01,  1.9445e-01,  1.7038e-01],\n",
      "        [ 1.9357e-01,  1.7155e-01,  1.8167e-01,  1.6928e-01,  1.9630e-01,\n",
      "          1.9334e-01,  1.8497e-01,  1.7827e-01,  1.7679e-01,  1.7333e-01,\n",
      "          1.6033e-01,  1.5809e-01,  2.0858e-01,  2.0109e-01,  1.2679e-01],\n",
      "        [ 5.4968e-02,  5.1587e-02,  6.2854e-02,  5.6617e-02,  6.1994e-02,\n",
      "          6.5128e-02,  6.1807e-02,  5.8180e-02,  5.0493e-02,  5.2775e-02,\n",
      "          4.6064e-02,  5.4498e-02,  8.6029e-02,  7.0192e-02,  3.7163e-02],\n",
      "        [ 1.3793e-02,  1.3628e-02,  1.3427e-02,  1.3786e-02,  3.8463e-03,\n",
      "          3.9076e-03,  3.1763e-03,  1.3666e-02,  1.3760e-02,  1.3271e-02,\n",
      "          1.3741e-02,  1.3226e-02,  1.3633e-02,  1.3717e-02,  1.3469e-02],\n",
      "        [ 3.5258e-02,  3.4714e-02,  3.4110e-02,  3.5319e-02,  3.5392e-02,\n",
      "          3.5712e-02,  3.3188e-02,  3.4910e-02,  3.5151e-02,  3.3472e-02,\n",
      "          3.5148e-02,  3.3447e-02,  3.4787e-02,  3.4984e-02,  3.4255e-02],\n",
      "        [ 1.0427e-01,  8.8123e-02,  1.0225e-01,  9.0680e-02,  1.0926e-01,\n",
      "          1.0942e-01,  1.0395e-01,  9.7182e-02,  8.9764e-02,  9.0852e-02,\n",
      "          7.8625e-02,  8.3251e-02,  1.2975e-01,  1.1755e-01,  5.3994e-02],\n",
      "        [ 1.4347e-01,  1.2895e-01,  1.4247e-01,  1.3166e-01,  1.4996e-01,\n",
      "          1.5073e-01,  1.4259e-01,  1.3680e-01,  1.3145e-01,  1.3158e-01,\n",
      "          1.2018e-01,  1.2303e-01,  1.6997e-01,  1.5742e-01,  9.6682e-02],\n",
      "        [ 3.0857e-01,  2.9081e-01,  3.0535e-01,  2.9241e-01,  3.1548e-01,\n",
      "          3.1425e-01,  3.0708e-01,  2.9877e-01,  2.9462e-01,  2.9524e-01,\n",
      "          2.7964e-01,  2.8198e-01,  3.3880e-01,  3.2375e-01,  2.5171e-01],\n",
      "        [ 3.7517e-01,  3.6695e-01,  3.6954e-01,  3.7093e-01,  3.7217e-01,\n",
      "          3.7175e-01,  3.7089e-01,  3.7274e-01,  3.6844e-01,  3.6898e-01,\n",
      "          3.6870e-01,  3.6521e-01,  3.8465e-01,  3.7522e-01,  3.6663e-01],\n",
      "        [-5.9414e-02, -6.1334e-02, -5.2881e-02, -5.5687e-02, -5.5834e-02,\n",
      "         -5.1399e-02, -5.4428e-02, -5.4711e-02, -6.4017e-02, -6.2448e-02,\n",
      "         -6.3915e-02, -5.7111e-02, -4.4315e-02, -5.0772e-02, -6.8659e-02],\n",
      "        [-8.3846e-02, -7.6716e-02, -7.0334e-02, -7.0872e-02, -7.6203e-02,\n",
      "         -7.0788e-02, -7.4098e-02, -7.3983e-02, -8.0416e-02, -7.9047e-02,\n",
      "         -7.8508e-02, -6.9405e-02, -5.8389e-02, -7.1016e-02, -7.4382e-02],\n",
      "        [ 2.8037e-01,  2.7004e-01,  2.7975e-01,  2.7343e-01,  2.8403e-01,\n",
      "          2.8377e-01,  2.8062e-01,  2.7618e-01,  2.7193e-01,  2.7466e-01,\n",
      "          2.6532e-01,  2.6682e-01,  3.0311e-01,  2.9014e-01,  2.5342e-01],\n",
      "        [ 2.7461e-01,  2.6310e-01,  2.7429e-01,  2.6578e-01,  2.7962e-01,\n",
      "          2.7813e-01,  2.7575e-01,  2.6861e-01,  2.6521e-01,  2.6954e-01,\n",
      "          2.5685e-01,  2.5914e-01,  3.0137e-01,  2.8672e-01,  2.4328e-01],\n",
      "        [-3.4487e-01, -3.3179e-01, -3.2593e-01, -3.2245e-01, -3.4147e-01,\n",
      "         -3.3238e-01, -3.2949e-01, -3.2644e-01, -3.4106e-01, -3.3581e-01,\n",
      "         -3.2928e-01, -3.1487e-01, -3.3329e-01, -3.3751e-01, -3.1268e-01],\n",
      "        [-1.7651e-01, -1.6847e-01, -1.7055e-01, -1.6493e-01, -1.7627e-01,\n",
      "         -1.7144e-01, -1.7381e-01, -1.6780e-01, -1.7119e-01, -1.7311e-01,\n",
      "         -1.6464e-01, -1.6210e-01, -1.7345e-01, -1.7655e-01, -1.5453e-01],\n",
      "        [-4.0921e-01, -3.9591e-01, -3.8498e-01, -3.8790e-01, -4.0003e-01,\n",
      "         -3.9113e-01, -3.8833e-01, -3.9148e-01, -4.0558e-01, -3.9790e-01,\n",
      "         -3.9914e-01, -3.7958e-01, -3.8674e-01, -3.9390e-01, -3.8866e-01],\n",
      "        [-2.2784e-01, -2.1964e-01, -2.2475e-01, -2.1564e-01, -2.3125e-01,\n",
      "         -2.2592e-01, -2.2785e-01, -2.1828e-01, -2.2267e-01, -2.2627e-01,\n",
      "         -2.1288e-01, -2.1223e-01, -2.3178e-01, -2.3272e-01, -1.9953e-01],\n",
      "        [ 4.3211e-01,  4.2239e-01,  4.2523e-01,  4.2358e-01,  4.3444e-01,\n",
      "          4.3447e-01,  4.2504e-01,  4.2633e-01,  4.2685e-01,  4.2037e-01,\n",
      "          4.1793e-01,  4.1336e-01,  4.4724e-01,  4.3694e-01,  4.0222e-01],\n",
      "        [ 2.8851e-01,  2.8813e-01,  2.9798e-01,  2.9165e-01,  2.9762e-01,\n",
      "          3.0068e-01,  2.9612e-01,  2.9126e-01,  2.8858e-01,  2.9144e-01,\n",
      "          2.8147e-01,  2.8708e-01,  3.1193e-01,  3.0196e-01,  2.7353e-01],\n",
      "        [ 2.7254e-01,  2.7445e-01,  2.8079e-01,  2.8103e-01,  2.7757e-01,\n",
      "          2.8206e-01,  2.7851e-01,  2.7975e-01,  2.7276e-01,  2.7283e-01,\n",
      "          2.7282e-01,  2.7799e-01,  2.9400e-01,  2.8238e-01,  2.7273e-01],\n",
      "        [ 6.3088e-03,  3.0559e-04,  5.0097e-03,  3.4124e-04,  1.0322e-02,\n",
      "          1.1826e-02,  3.4089e-03,  3.1819e-03,  1.8374e-03, -2.2256e-03,\n",
      "         -4.8192e-03, -4.7689e-03,  1.3763e-02,  1.1392e-02, -1.9603e-02],\n",
      "        [ 2.7356e-01,  2.6448e-01,  2.6514e-01,  2.6684e-01,  2.6883e-01,\n",
      "          2.6777e-01,  2.6681e-01,  2.6974e-01,  2.6646e-01,  2.6564e-01,\n",
      "          2.6695e-01,  2.6229e-01,  2.7865e-01,  2.7101e-01,  2.6373e-01],\n",
      "        [ 2.1126e-01,  2.0226e-01,  2.0060e-01,  2.0508e-01,  2.0246e-01,\n",
      "          2.0210e-01,  2.0236e-01,  2.0804e-01,  2.0417e-01,  2.0377e-01,\n",
      "          2.0774e-01,  2.0071e-01,  2.0174e-01,  2.0203e-01,  2.0807e-01],\n",
      "        [ 1.3302e-01,  1.1775e-01,  1.2245e-01,  1.2208e-01,  1.2988e-01,\n",
      "          1.3064e-01,  1.2126e-01,  1.2677e-01,  1.2028e-01,  1.1510e-01,\n",
      "          1.1872e-01,  1.1281e-01,  1.3794e-01,  1.3267e-01,  1.0366e-01],\n",
      "        [-4.2814e-02, -4.2169e-02, -4.2055e-02, -4.0566e-02, -4.1517e-02,\n",
      "         -3.9582e-02, -4.3571e-02, -4.0791e-02, -4.2512e-02, -4.6165e-02,\n",
      "         -4.2238e-02, -4.1613e-02, -3.3716e-02, -4.0022e-02, -4.3320e-02],\n",
      "        [-1.4242e-01, -1.3516e-01, -1.3267e-01, -1.2701e-01, -1.4229e-01,\n",
      "         -1.3595e-01, -1.3741e-01, -1.3016e-01, -1.3966e-01, -1.3809e-01,\n",
      "         -1.2895e-01, -1.2444e-01, -1.3888e-01, -1.4033e-01, -1.1681e-01]])\n",
      "fc4.bias tensor([ 0.0414,  0.2351,  0.5165,  0.2345,  0.3098,  0.5465,  0.0223,  0.1117,\n",
      "         0.5899,  0.5577,  0.1856, -0.2199,  0.7287,  0.6822,  0.0884,  0.0850,\n",
      "         1.1501,  0.7075,  1.2428,  0.8255, -0.3346, -0.0400, -0.0535,  0.5407,\n",
      "        -0.0914,  0.0392,  0.8356,  0.3832,  0.7580])\n"
     ]
    }
   ],
   "source": [
    "for name, param in sae.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/baseball.pth'\n",
    "torch.save(sae.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2151,  0.7205,  0.5957,  0.5070,  0.5714,  0.6317,  0.0393,  0.1625,\n",
       "          0.7317,  0.7589,  0.6254,  0.3242,  0.6451,  0.5739,  0.4944,  0.4820,\n",
       "          0.6655,  0.4587,  0.6663,  0.5001,  0.2897,  0.3888,  0.3542,  0.5444,\n",
       "          0.3012,  0.3383,  1.0160,  0.3224,  0.5615],\n",
       "        [ 0.1848,  0.6357,  0.5819,  0.4593,  0.5257,  0.6168,  0.0363,  0.1536,\n",
       "          0.7069,  0.7238,  0.5485,  0.2291,  0.6597,  0.5929,  0.4235,  0.4126,\n",
       "          0.7502,  0.5022,  0.7671,  0.5569,  0.1806,  0.3139,  0.2829,  0.5437,\n",
       "          0.2326,  0.2861,  0.9844,  0.3330,  0.5959],\n",
       "        [ 0.1977,  0.6718,  0.5878,  0.4796,  0.5451,  0.6232,  0.0376,  0.1574,\n",
       "          0.7174,  0.7387,  0.5812,  0.2695,  0.6535,  0.5848,  0.4536,  0.4421,\n",
       "          0.7141,  0.4837,  0.7242,  0.5328,  0.2270,  0.3457,  0.3132,  0.5440,\n",
       "          0.2618,  0.3083,  0.9978,  0.3285,  0.5813],\n",
       "        [ 0.2284,  0.7577,  0.6018,  0.5278,  0.5914,  0.6382,  0.0406,  0.1664,\n",
       "          0.7425,  0.7743,  0.6590,  0.3658,  0.6387,  0.5657,  0.5255,  0.5124,\n",
       "          0.6284,  0.4397,  0.6222,  0.4752,  0.3375,  0.4216,  0.3854,  0.5447,\n",
       "          0.3313,  0.3612,  1.0298,  0.3177,  0.5465],\n",
       "        [ 0.1248,  0.4681,  0.5546,  0.3653,  0.4354,  0.5874,  0.0304,  0.1361,\n",
       "          0.6579,  0.6543,  0.3967,  0.0413,  0.6886,  0.6302,  0.2833,  0.2755,\n",
       "          0.9175,  0.5881,  0.9661,  0.6693, -0.0349,  0.1658,  0.1422,  0.5425,\n",
       "          0.0971,  0.1828,  0.9222,  0.3540,  0.6637],\n",
       "        [ 0.2635,  0.8557,  0.6178,  0.5829,  0.6442,  0.6554,  0.0440,  0.1766,\n",
       "          0.7712,  0.8150,  0.7479,  0.4757,  0.6218,  0.5438,  0.6075,  0.5926,\n",
       "          0.5305,  0.3894,  0.5057,  0.4094,  0.4636,  0.5083,  0.4678,  0.5454,\n",
       "          0.4106,  0.4217,  1.0662,  0.3054,  0.5068]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = sae(test_set_1)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1463, 0.7667, 0.1000, 0.0000, 0.5455, 0.4444, 0.0000, 0.0000, 0.6294,\n",
       "         0.6681, 0.5488, 0.8824, 0.4629, 0.6667, 0.7324, 0.7538, 0.3653, 0.6587,\n",
       "         0.3386, 0.7037, 0.3023, 0.4607, 0.0000, 0.2381, 0.6418, 0.7007, 1.0000,\n",
       "         0.6512, 0.1176],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0455, 0.7778, 1.0000, 1.0000, 0.0521,\n",
       "         0.0733, 0.1402, 0.2353, 0.0000, 0.0222, 0.1690, 0.1538, 0.1301, 0.6779,\n",
       "         0.0394, 0.6667, 0.9535, 1.0000, 0.7927, 0.6190, 0.4965, 0.7211, 1.0000,\n",
       "         0.2982, 0.1373],\n",
       "        [0.2195, 0.8667, 0.0000, 0.0000, 0.5909, 0.4444, 0.0000, 0.0000, 0.6636,\n",
       "         0.7414, 0.6280, 0.4118, 0.6157, 1.0000, 0.7465, 0.7385, 0.7169, 1.0000,\n",
       "         0.5984, 1.0000, 0.4419, 0.7438, 0.6098, 0.2262, 0.5816, 0.5476, 1.0000,\n",
       "         1.0000, 0.0000],\n",
       "        [0.0000, 0.5667, 0.2000, 0.1667, 0.1818, 0.7778, 0.0000, 0.0000, 0.3869,\n",
       "         0.4052, 0.4390, 0.2941, 0.1878, 0.0889, 0.3803, 0.3846, 0.0000, 0.1635,\n",
       "         0.0000, 0.1667, 0.6977, 0.4989, 0.4878, 0.4286, 0.4078, 0.4830, 1.0000,\n",
       "         0.3834, 0.2549],\n",
       "        [0.7561, 0.0000, 0.0000, 0.0000, 0.0000, 0.2222, 0.8276, 0.2500, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0480, 0.0000, 0.0000, 0.0000, 0.9452, 0.8317,\n",
       "         0.9134, 0.8889, 0.2674, 0.4494, 0.7073, 1.0000, 0.0177, 0.0306, 1.0000,\n",
       "         0.1217, 0.1176],\n",
       "        [0.2439, 0.9000, 0.0000, 0.0000, 0.5455, 0.8889, 0.0000, 0.0000, 0.7613,\n",
       "         0.7989, 0.7805, 0.5294, 0.6114, 0.1778, 0.6479, 0.6154, 0.4886, 0.0000,\n",
       "         0.4724, 0.0000, 0.5698, 0.3506, 0.5976, 0.4107, 0.3475, 0.3673, 1.0000,\n",
       "         0.5173, 0.9020]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1299, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = criterion(test_set_1,outputs)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
