{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>SV</th>\n",
       "      <th>HLD</th>\n",
       "      <th>IP</th>\n",
       "      <th>BF</th>\n",
       "      <th>...</th>\n",
       "      <th>BB%</th>\n",
       "      <th>AVG</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LOB%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>FIP</th>\n",
       "      <th>LL</th>\n",
       "      <th>PF</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182.2</td>\n",
       "      <td>734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.232</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.780</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0250</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.817</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158.1</td>\n",
       "      <td>674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.260</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.717</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190.1</td>\n",
       "      <td>786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1.240</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.792</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194.2</td>\n",
       "      <td>773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.226</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.787</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206.3</td>\n",
       "      <td>821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.222</td>\n",
       "      <td>1.013</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.798</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.799</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.7</td>\n",
       "      <td>654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.757</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0450</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>57.3</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.266</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.821</td>\n",
       "      <td>2.67</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.222</td>\n",
       "      <td>1.159</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.755</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.1023</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.244</td>\n",
       "      <td>1.050</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.789</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>47.7</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.207</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.885</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.786</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     G  GS  CG  SHO   W  L  SV  HLD     IP   BF  ...    BB%    AVG   WHIP  \\\n",
       "0   27  27   1    0   9  9   0    0  182.2  734  ...  0.063  0.232  1.090   \n",
       "1   28  28  10    6  18  6   0    0  232.0  885  ...  0.041  0.190  0.828   \n",
       "2   28  28   0    0  12  7   0    0  158.1  674  ...  0.070  0.250  1.260   \n",
       "3   31  30   0    0  17  6   0    0  190.1  786  ...  0.048  0.270  1.240   \n",
       "4   30  30   0    0  20  3   0    0  194.2  773  ...  0.038  0.226  1.000   \n",
       "5   28  27   8    2  24  0   1    0  212.0  822  ...  0.039  0.218  0.943   \n",
       "6   29  29   5    0  15  8   0    0  206.3  821  ...  0.050  0.222  1.013   \n",
       "7   21  10   0    1  10  4   0    1  140.0  548  ...  0.082  0.184  0.957   \n",
       "8   23  23   1    0  14  4   0    0  163.7  654  ...  0.069  0.210  1.033   \n",
       "9   58   0   0    0   3  7  29    8   57.3  240  ...  0.067  0.266  1.273   \n",
       "10  26  26   0    0  15  4   0    0  170.0  705  ...  0.085  0.222  1.159   \n",
       "11  17  17   2    1   6  7   0    0  119.0  471  ...  0.040  0.244  1.050   \n",
       "12  48   0   0    0   2  2  24    2   47.7  189  ...  0.079  0.207  1.028   \n",
       "13  27  27   0    0  14  8   0    0  188.0  745  ...  0.031  0.233  0.984   \n",
       "\n",
       "    BABIP   LOB%   ERA   FIP    LL      PF  WAR  \n",
       "0   0.320  0.780  2.66  2.41  0.50  1.0250  3.8  \n",
       "1   0.280  0.817  1.44  1.46  0.75  0.9870  4.7  \n",
       "2   0.309  0.717  4.09  4.40  0.50  0.9710  2.0  \n",
       "3   0.338  0.792  2.51  2.77  0.50  0.9710  0.6  \n",
       "4   0.285  0.787  2.50  2.87  0.50  0.9380  0.8  \n",
       "5   0.278  0.863  1.27  2.35  0.75  1.0010  2.9  \n",
       "6   0.282  0.798  2.09  2.38  0.75  0.9950  2.9  \n",
       "7   0.277  0.799  1.86  2.28  0.75  0.9870  1.0  \n",
       "8   0.256  0.757  3.08  3.52  0.75  1.0450  0.2  \n",
       "9   0.321  0.821  2.67  3.58  0.75  0.9870  0.3  \n",
       "10  0.306  0.755  2.91  3.07  0.75  1.1023 -0.4  \n",
       "11  0.296  0.789  2.42  2.88  0.75  1.0010  0.9  \n",
       "12  0.314  0.885  1.32  1.55  0.75  0.9580  0.2  \n",
       "13  0.305  0.786  2.25  2.54  0.75  1.0230  4.2  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('player_stat_.csv')\n",
    "data = data.drop(['player'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features deletion\n",
    "data = pd.read_csv('player_stat_feature_deletion.csv')\n",
    "data = data.drop(['player'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 500)\n",
    "# data = pd.read_csv('player_stat_.csv')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72978839, 0.78304598, 0.72560976, 0.64705882, 0.71179039,\n",
       "        0.95555556, 0.71830986, 0.72307692, 0.80821918, 0.5625    ,\n",
       "        0.7480315 , 0.59259259, 0.55813953, 0.58876404, 0.7804878 ,\n",
       "        0.375     , 0.4929078 , 0.32312925, 0.        , 0.52951917,\n",
       "        0.82352941],\n",
       "       [1.        , 1.        , 0.74390244, 0.23529412, 1.        ,\n",
       "        0.46666667, 0.49295775, 0.46153846, 0.89041096, 0.14423077,\n",
       "        0.95275591, 0.18518519, 0.06976744, 0.        , 0.29268293,\n",
       "        0.5952381 , 0.06028369, 0.        , 1.        , 0.29823494,\n",
       "        1.        ],\n",
       "       [0.59902333, 0.69683908, 0.7195122 , 1.        , 0.49781659,\n",
       "        0.71111111, 1.        , 1.        , 0.53424658, 0.75480769,\n",
       "        0.37795276, 0.72222222, 0.76744186, 0.97078652, 0.64634146,\n",
       "        0.        , 1.        , 1.        , 0.        , 0.2008521 ,\n",
       "        0.47058824],\n",
       "       [0.77265328, 0.85775862, 1.        , 0.70588235, 0.58078603,\n",
       "        0.51111111, 0.8028169 , 0.70769231, 0.38812785, 0.33653846,\n",
       "        0.2992126 , 0.31481481, 1.        , 0.9258427 , 1.        ,\n",
       "        0.44642857, 0.43971631, 0.44557823, 0.        , 0.2008521 ,\n",
       "        0.19607843],\n",
       "       [0.79489962, 0.83908046, 0.79878049, 0.70588235, 0.62008734,\n",
       "        0.31111111, 0.70422535, 0.72307692, 0.44063927, 0.11538462,\n",
       "        0.42519685, 0.12962963, 0.48837209, 0.38651685, 0.35365854,\n",
       "        0.41666667, 0.43617021, 0.47959184, 0.        , 0.        ,\n",
       "        0.23529412],\n",
       "       [0.89148128, 0.90948276, 0.81707317, 0.29411765, 0.59388646,\n",
       "        0.37777778, 0.3943662 , 0.35384615, 0.21917808, 0.125     ,\n",
       "        0.2519685 , 0.14814815, 0.39534884, 0.25842697, 0.26829268,\n",
       "        0.86904762, 0.        , 0.30272109, 1.        , 0.38344492,\n",
       "        0.64705882],\n",
       "       [0.86055345, 0.90804598, 0.81707317, 0.23529412, 0.55895197,\n",
       "        0.57777778, 0.5915493 , 0.63076923, 0.18721461, 0.33173077,\n",
       "        0.17322835, 0.35185185, 0.44186047, 0.41573034, 0.31707317,\n",
       "        0.48214286, 0.29078014, 0.31292517, 1.        , 0.34692635,\n",
       "        0.64705882],\n",
       "       [0.50081389, 0.5158046 , 0.33536585, 0.17647059, 0.55458515,\n",
       "        0.66666667, 0.36619718, 0.33846154, 1.        , 0.86057692,\n",
       "        1.        , 0.94444444, 0.        , 0.28988764, 0.25609756,\n",
       "        0.48809524, 0.20921986, 0.27891156, 1.        , 0.29823494,\n",
       "        0.2745098 ],\n",
       "       [0.62940857, 0.66810345, 0.54878049, 0.88235294, 0.4628821 ,\n",
       "        0.66666667, 0.73239437, 0.75384615, 0.3652968 , 0.65865385,\n",
       "        0.33858268, 0.7037037 , 0.30232558, 0.46067416, 0.        ,\n",
       "        0.23809524, 0.64184397, 0.70068027, 1.        , 0.65124772,\n",
       "        0.11764706],\n",
       "       [0.05208899, 0.07327586, 0.1402439 , 0.23529412, 0.        ,\n",
       "        0.02222222, 0.16901408, 0.15384615, 0.13013699, 0.67788462,\n",
       "        0.03937008, 0.66666667, 0.95348837, 1.        , 0.79268293,\n",
       "        0.61904762, 0.4964539 , 0.72108844, 1.        , 0.29823494,\n",
       "        0.1372549 ],\n",
       "       [0.66359197, 0.74137931, 0.62804878, 0.41176471, 0.61572052,\n",
       "        1.        , 0.74647887, 0.73846154, 0.71689498, 1.        ,\n",
       "        0.5984252 , 1.        , 0.44186047, 0.74382022, 0.6097561 ,\n",
       "        0.22619048, 0.58156028, 0.54761905, 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.38686923, 0.40517241, 0.43902439, 0.29411765, 0.18777293,\n",
       "        0.08888889, 0.38028169, 0.38461538, 0.        , 0.16346154,\n",
       "        0.        , 0.16666667, 0.69767442, 0.4988764 , 0.48780488,\n",
       "        0.42857143, 0.40780142, 0.4829932 , 1.        , 0.38344492,\n",
       "        0.25490196],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.04803493,\n",
       "        0.        , 0.        , 0.        , 0.94520548, 0.83173077,\n",
       "        0.91338583, 0.88888889, 0.26744186, 0.4494382 , 0.70731707,\n",
       "        1.        , 0.0177305 , 0.03061224, 1.        , 0.12172855,\n",
       "        0.11764706],\n",
       "       [0.76125882, 0.79885057, 0.7804878 , 0.52941176, 0.61135371,\n",
       "        0.17777778, 0.64788732, 0.61538462, 0.48858447, 0.        ,\n",
       "        0.47244094, 0.        , 0.56976744, 0.3505618 , 0.59756098,\n",
       "        0.41071429, 0.34751773, 0.36734694, 1.        , 0.51734632,\n",
       "        0.90196078]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm = (data - data.min()) / (data.max() - data.min())\n",
    "data_norm = data_norm.to_numpy()\n",
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_1 = torch.FloatTensor(data_norm[0:8])\n",
    "test_set_1 = torch.FloatTensor(data_norm[8:14])\n",
    "# test_set_1 = torch[8:14]\n",
    "# training_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_player = len(training_set_1)\n",
    "nb_stats = data_norm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(21, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 16)\n",
    "        self.fc4 = nn.Linear(16, 21)\n",
    "#         self.fc1 = nn.Linear(29, 10)\n",
    "#         self.fc2 = nn.Linear(10, 1)\n",
    "#         self.fc3 = nn.Linear(1, 10)\n",
    "#         self.fc4 = nn.Linear(10, 29)\n",
    "        self.activation = nn.Sigmoid()\n",
    "#         self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.4512)\n",
      "epoch: 2 loss: tensor(0.2701)\n",
      "epoch: 3 loss: tensor(0.2428)\n",
      "epoch: 4 loss: tensor(0.2414)\n",
      "epoch: 5 loss: tensor(0.2396)\n",
      "epoch: 6 loss: tensor(0.2379)\n",
      "epoch: 7 loss: tensor(0.2368)\n",
      "epoch: 8 loss: tensor(0.2359)\n",
      "epoch: 9 loss: tensor(0.2353)\n",
      "epoch: 10 loss: tensor(0.2349)\n",
      "epoch: 11 loss: tensor(0.2346)\n",
      "epoch: 12 loss: tensor(0.2343)\n",
      "epoch: 13 loss: tensor(0.2341)\n",
      "epoch: 14 loss: tensor(0.2339)\n",
      "epoch: 15 loss: tensor(0.2337)\n",
      "epoch: 16 loss: tensor(0.2336)\n",
      "epoch: 17 loss: tensor(0.2335)\n",
      "epoch: 18 loss: tensor(0.2333)\n",
      "epoch: 19 loss: tensor(0.2332)\n",
      "epoch: 20 loss: tensor(0.2331)\n",
      "epoch: 21 loss: tensor(0.2331)\n",
      "epoch: 22 loss: tensor(0.2330)\n",
      "epoch: 23 loss: tensor(0.2330)\n",
      "epoch: 24 loss: tensor(0.2329)\n",
      "epoch: 25 loss: tensor(0.2329)\n",
      "epoch: 26 loss: tensor(0.2329)\n",
      "epoch: 27 loss: tensor(0.2328)\n",
      "epoch: 28 loss: tensor(0.2327)\n",
      "epoch: 29 loss: tensor(0.2327)\n",
      "epoch: 30 loss: tensor(0.2327)\n",
      "epoch: 31 loss: tensor(0.2326)\n",
      "epoch: 32 loss: tensor(0.2327)\n",
      "epoch: 33 loss: tensor(0.2326)\n",
      "epoch: 34 loss: tensor(0.2326)\n",
      "epoch: 35 loss: tensor(0.2326)\n",
      "epoch: 36 loss: tensor(0.2324)\n",
      "epoch: 37 loss: tensor(0.2325)\n",
      "epoch: 38 loss: tensor(0.2324)\n",
      "epoch: 39 loss: tensor(0.2325)\n",
      "epoch: 40 loss: tensor(0.2325)\n",
      "epoch: 41 loss: tensor(0.2325)\n",
      "epoch: 42 loss: tensor(0.2325)\n",
      "epoch: 43 loss: tensor(0.2325)\n",
      "epoch: 44 loss: tensor(0.2325)\n",
      "epoch: 45 loss: tensor(0.2325)\n",
      "epoch: 46 loss: tensor(0.2325)\n",
      "epoch: 47 loss: tensor(0.2325)\n",
      "epoch: 48 loss: tensor(0.2326)\n",
      "epoch: 49 loss: tensor(0.2326)\n",
      "epoch: 50 loss: tensor(0.2326)\n",
      "epoch: 51 loss: tensor(0.2326)\n",
      "epoch: 52 loss: tensor(0.2326)\n",
      "epoch: 53 loss: tensor(0.2326)\n",
      "epoch: 54 loss: tensor(0.2326)\n",
      "epoch: 55 loss: tensor(0.2326)\n",
      "epoch: 56 loss: tensor(0.2326)\n",
      "epoch: 57 loss: tensor(0.2326)\n",
      "epoch: 58 loss: tensor(0.2326)\n",
      "epoch: 59 loss: tensor(0.2326)\n",
      "epoch: 60 loss: tensor(0.2326)\n",
      "epoch: 61 loss: tensor(0.2326)\n",
      "epoch: 62 loss: tensor(0.2326)\n",
      "epoch: 63 loss: tensor(0.2326)\n",
      "epoch: 64 loss: tensor(0.2326)\n",
      "epoch: 65 loss: tensor(0.2326)\n",
      "epoch: 66 loss: tensor(0.2326)\n",
      "epoch: 67 loss: tensor(0.2326)\n",
      "epoch: 68 loss: tensor(0.2327)\n",
      "epoch: 69 loss: tensor(0.2327)\n",
      "epoch: 70 loss: tensor(0.2327)\n",
      "epoch: 71 loss: tensor(0.2327)\n",
      "epoch: 72 loss: tensor(0.2327)\n",
      "epoch: 73 loss: tensor(0.2327)\n",
      "epoch: 74 loss: tensor(0.2327)\n",
      "epoch: 75 loss: tensor(0.2327)\n",
      "epoch: 76 loss: tensor(0.2327)\n",
      "epoch: 77 loss: tensor(0.2327)\n",
      "epoch: 78 loss: tensor(0.2327)\n",
      "epoch: 79 loss: tensor(0.2327)\n",
      "epoch: 80 loss: tensor(0.2327)\n",
      "epoch: 81 loss: tensor(0.2327)\n",
      "epoch: 82 loss: tensor(0.2327)\n",
      "epoch: 83 loss: tensor(0.2327)\n",
      "epoch: 84 loss: tensor(0.2327)\n",
      "epoch: 85 loss: tensor(0.2327)\n",
      "epoch: 86 loss: tensor(0.2327)\n",
      "epoch: 87 loss: tensor(0.2327)\n",
      "epoch: 88 loss: tensor(0.2327)\n",
      "epoch: 89 loss: tensor(0.2327)\n",
      "epoch: 90 loss: tensor(0.2327)\n",
      "epoch: 91 loss: tensor(0.2327)\n",
      "epoch: 92 loss: tensor(0.2327)\n",
      "epoch: 93 loss: tensor(0.2327)\n",
      "epoch: 94 loss: tensor(0.2327)\n",
      "epoch: 95 loss: tensor(0.2327)\n",
      "epoch: 96 loss: tensor(0.2327)\n",
      "epoch: 97 loss: tensor(0.2327)\n",
      "epoch: 98 loss: tensor(0.2327)\n",
      "epoch: 99 loss: tensor(0.2327)\n",
      "epoch: 100 loss: tensor(0.2327)\n",
      "epoch: 101 loss: tensor(0.2327)\n",
      "epoch: 102 loss: tensor(0.2327)\n",
      "epoch: 103 loss: tensor(0.2327)\n",
      "epoch: 104 loss: tensor(0.2327)\n",
      "epoch: 105 loss: tensor(0.2327)\n",
      "epoch: 106 loss: tensor(0.2327)\n",
      "epoch: 107 loss: tensor(0.2327)\n",
      "epoch: 108 loss: tensor(0.2327)\n",
      "epoch: 109 loss: tensor(0.2327)\n",
      "epoch: 110 loss: tensor(0.2327)\n",
      "epoch: 111 loss: tensor(0.2327)\n",
      "epoch: 112 loss: tensor(0.2327)\n",
      "epoch: 113 loss: tensor(0.2327)\n",
      "epoch: 114 loss: tensor(0.2327)\n",
      "epoch: 115 loss: tensor(0.2327)\n",
      "epoch: 116 loss: tensor(0.2327)\n",
      "epoch: 117 loss: tensor(0.2327)\n",
      "epoch: 118 loss: tensor(0.2327)\n",
      "epoch: 119 loss: tensor(0.2327)\n",
      "epoch: 120 loss: tensor(0.2327)\n",
      "epoch: 121 loss: tensor(0.2327)\n",
      "epoch: 122 loss: tensor(0.2327)\n",
      "epoch: 123 loss: tensor(0.2327)\n",
      "epoch: 124 loss: tensor(0.2327)\n",
      "epoch: 125 loss: tensor(0.2327)\n",
      "epoch: 126 loss: tensor(0.2327)\n",
      "epoch: 127 loss: tensor(0.2327)\n",
      "epoch: 128 loss: tensor(0.2327)\n",
      "epoch: 129 loss: tensor(0.2327)\n",
      "epoch: 130 loss: tensor(0.2327)\n",
      "epoch: 131 loss: tensor(0.2327)\n",
      "epoch: 132 loss: tensor(0.2327)\n",
      "epoch: 133 loss: tensor(0.2327)\n",
      "epoch: 134 loss: tensor(0.2327)\n",
      "epoch: 135 loss: tensor(0.2327)\n",
      "epoch: 136 loss: tensor(0.2327)\n",
      "epoch: 137 loss: tensor(0.2327)\n",
      "epoch: 138 loss: tensor(0.2327)\n",
      "epoch: 139 loss: tensor(0.2327)\n",
      "epoch: 140 loss: tensor(0.2327)\n",
      "epoch: 141 loss: tensor(0.2327)\n",
      "epoch: 142 loss: tensor(0.2327)\n",
      "epoch: 143 loss: tensor(0.2327)\n",
      "epoch: 144 loss: tensor(0.2327)\n",
      "epoch: 145 loss: tensor(0.2327)\n",
      "epoch: 146 loss: tensor(0.2327)\n",
      "epoch: 147 loss: tensor(0.2327)\n",
      "epoch: 148 loss: tensor(0.2327)\n",
      "epoch: 149 loss: tensor(0.2327)\n",
      "epoch: 150 loss: tensor(0.2327)\n",
      "epoch: 151 loss: tensor(0.2327)\n",
      "epoch: 152 loss: tensor(0.2327)\n",
      "epoch: 153 loss: tensor(0.2327)\n",
      "epoch: 154 loss: tensor(0.2327)\n",
      "epoch: 155 loss: tensor(0.2327)\n",
      "epoch: 156 loss: tensor(0.2327)\n",
      "epoch: 157 loss: tensor(0.2327)\n",
      "epoch: 158 loss: tensor(0.2327)\n",
      "epoch: 159 loss: tensor(0.2327)\n",
      "epoch: 160 loss: tensor(0.2327)\n",
      "epoch: 161 loss: tensor(0.2327)\n",
      "epoch: 162 loss: tensor(0.2327)\n",
      "epoch: 163 loss: tensor(0.2327)\n",
      "epoch: 164 loss: tensor(0.2327)\n",
      "epoch: 165 loss: tensor(0.2327)\n",
      "epoch: 166 loss: tensor(0.2327)\n",
      "epoch: 167 loss: tensor(0.2327)\n",
      "epoch: 168 loss: tensor(0.2327)\n",
      "epoch: 169 loss: tensor(0.2327)\n",
      "epoch: 170 loss: tensor(0.2327)\n",
      "epoch: 171 loss: tensor(0.2327)\n",
      "epoch: 172 loss: tensor(0.2327)\n",
      "epoch: 173 loss: tensor(0.2327)\n",
      "epoch: 174 loss: tensor(0.2327)\n",
      "epoch: 175 loss: tensor(0.2327)\n",
      "epoch: 176 loss: tensor(0.2327)\n",
      "epoch: 177 loss: tensor(0.2327)\n",
      "epoch: 178 loss: tensor(0.2327)\n",
      "epoch: 179 loss: tensor(0.2327)\n",
      "epoch: 180 loss: tensor(0.2327)\n",
      "epoch: 181 loss: tensor(0.2327)\n",
      "epoch: 182 loss: tensor(0.2327)\n",
      "epoch: 183 loss: tensor(0.2327)\n",
      "epoch: 184 loss: tensor(0.2327)\n",
      "epoch: 185 loss: tensor(0.2327)\n",
      "epoch: 186 loss: tensor(0.2327)\n",
      "epoch: 187 loss: tensor(0.2327)\n",
      "epoch: 188 loss: tensor(0.2327)\n",
      "epoch: 189 loss: tensor(0.2327)\n",
      "epoch: 190 loss: tensor(0.2327)\n",
      "epoch: 191 loss: tensor(0.2327)\n",
      "epoch: 192 loss: tensor(0.2327)\n",
      "epoch: 193 loss: tensor(0.2327)\n",
      "epoch: 194 loss: tensor(0.2327)\n",
      "epoch: 195 loss: tensor(0.2327)\n",
      "epoch: 196 loss: tensor(0.2327)\n",
      "epoch: 197 loss: tensor(0.2327)\n",
      "epoch: 198 loss: tensor(0.2327)\n",
      "epoch: 199 loss: tensor(0.2327)\n",
      "epoch: 200 loss: tensor(0.2327)\n",
      "test loss: tensor(0.2852)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200 #200\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_player in range(nb_player):\n",
    "        input = Variable(training_set_1[id_player]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        #Select only rating related columns to compute loss\n",
    "        target_ratings = target[:, :nb_stats]\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            output_ratings = output[:, :nb_stats]\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output_ratings, target_ratings)\n",
    "            mean_corrector = nb_stats/float(torch.sum(target.data > 0) + 1e-10)\n",
    "#             print(mean_corrector)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "    \n",
    "# Testing the SAE\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_player in range(len(test_set_1)):\n",
    "    input = Variable(test_set_1[id_player]).unsqueeze(0)\n",
    "    target = Variable(test_set_1[id_player]).unsqueeze(0)\n",
    "    target_ratings = target[:, :nb_stats]\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        output_ratings = output[:, :nb_stats]\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output_ratings, target_ratings)\n",
    "        mean_corrector = nb_stats/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-5.0258e-03, -2.5123e-23, -5.0109e-03, -4.9885e-03,  5.0464e-03,\n",
       "          -3.3497e-23, -8.6881e-44, -5.0308e-03, -3.7745e-23, -3.8875e-23,\n",
       "          -2.5276e-23, -1.3300e-23, -4.9899e-03, -5.0077e-03, -2.7600e-23,\n",
       "          -2.5509e-23, -7.5368e-23,  4.9681e-03, -7.5368e-23, -7.1181e-23,\n",
       "           4.9792e-03, -5.0142e-03, -5.0130e-03, -5.0350e-03, -1.5769e-23,\n",
       "          -2.1021e-23, -5.0031e-03, -5.0307e-03,  5.0364e-03],\n",
       "         [ 1.3312e-43, -1.1070e-43,  4.9766e-03,  1.2191e-43, -8.4078e-45,\n",
       "          -5.7453e-44, -4.9352e-03,  7.9874e-44,  5.8855e-44,  9.1084e-44,\n",
       "           4.9702e-03, -1.0930e-43,  5.0257e-03,  6.1657e-44,  3.2230e-44,\n",
       "          -1.0650e-43,  4.9765e-03,  4.9686e-03,  9.8091e-44, -2.8026e-45,\n",
       "          -5.0116e-03, -4.9618e-03,  2.9427e-44, -6.8664e-44, -5.8855e-44,\n",
       "          -5.0188e-03, -8.5479e-44, -5.0014e-03,  5.0313e-03],\n",
       "         [-4.9726e-03, -2.1259e-16, -2.9427e-44, -1.0629e-16, -5.0207e-03,\n",
       "          -4.9761e-03,  4.9952e-03, -7.9720e-17, -5.0013e-03, -3.2896e-16,\n",
       "          -2.1388e-16, -1.1255e-16, -3.5369e-16, -4.2517e-16, -2.3355e-16,\n",
       "          -2.1586e-16, -5.0266e-03, -4.9796e-03, -6.3776e-16, -6.0233e-16,\n",
       "           2.8026e-44, -4.9944e-03, -4.9862e-03, -3.1129e-16, -1.3343e-16,\n",
       "          -1.7788e-16, -6.3776e-16, -4.9887e-03, -4.9592e-03],\n",
       "         [-4.9944e-03, -9.8091e-45,  4.9893e-03, -5.0269e-03,  5.6052e-45,\n",
       "          -4.2039e-45, -5.0059e-03,  5.0260e-03, -4.9826e-03, -5.0292e-03,\n",
       "           8.5479e-44, -1.2612e-44, -1.1210e-44,  4.9481e-03,  1.0510e-43,\n",
       "           5.0255e-03,  6.4460e-44,  1.2472e-43,  2.3822e-44, -4.9769e-03,\n",
       "          -5.0388e-03, -7.9874e-44, -7.1466e-44, -1.3032e-43, -4.9851e-03,\n",
       "          -5.0143e-03, -1.1771e-43, -5.0272e-03,  4.9850e-03],\n",
       "         [-4.9682e-03,  5.0471e-03,  4.9701e-03, -5.0161e-03,  4.9844e-03,\n",
       "           5.1848e-44,  3.2230e-44, -4.9594e-03, -4.9888e-03, -1.0229e-43,\n",
       "          -6.4460e-44, -4.9779e-03,  4.9882e-03,  1.0650e-43,  5.0398e-03,\n",
       "           1.4013e-45, -4.9982e-03,  1.3593e-43,  4.9861e-03,  4.9943e-03,\n",
       "          -4.9757e-03, -5.0021e-03,  1.1491e-43,  5.0100e-03,  1.1911e-43,\n",
       "           4.9650e-03, -5.6052e-44, -4.9794e-03, -5.0120e-03],\n",
       "         [-4.9842e-03, -5.4440e-21,  6.5861e-44,  4.9759e-03, -4.9827e-03,\n",
       "          -7.2586e-21, -4.9818e-03, -2.0415e-21, -5.0093e-03, -8.4241e-21,\n",
       "          -5.4772e-21,  5.0030e-03, -9.0574e-21, -4.9813e-03, -5.9807e-21,\n",
       "          -5.5277e-21, -4.9818e-03, -1.4055e-20,  4.9767e-03, -1.5425e-20,\n",
       "           3.9236e-44, -4.7344e-21, -4.1826e-21, -4.9887e-03, -3.4170e-21,\n",
       "          -5.0242e-03, -1.6332e-20,  5.0201e-03, -5.0336e-03],\n",
       "         [ 5.0151e-03, -5.6052e-44,  4.9701e-03, -4.9703e-03, -5.0350e-03,\n",
       "           8.4078e-45, -6.5861e-44,  4.9485e-03, -9.1084e-44,  5.0123e-03,\n",
       "          -1.8217e-44, -5.0309e-03, -4.9789e-03, -5.0762e-03,  4.9843e-03,\n",
       "          -4.6243e-44, -6.4460e-44,  5.0274e-03,  1.2612e-44, -5.0301e-03,\n",
       "           9.3887e-44,  6.4460e-44, -7.1466e-44, -5.0107e-03,  2.8026e-45,\n",
       "           8.6881e-44,  4.9757e-03,  4.9760e-03,  5.0596e-03],\n",
       "         [ 4.9950e-03,  9.1793e-25, -4.9897e-03,  4.5897e-25,  1.0014e-24,\n",
       "           1.2239e-24,  5.0332e-03,  3.4423e-25, -5.0092e-03,  4.9859e-03,\n",
       "           4.9587e-03,  4.8596e-25,  1.5272e-24, -4.9901e-03, -4.9899e-03,\n",
       "           9.3206e-25,  4.9757e-03,  2.3699e-24,  4.9811e-03, -4.9847e-03,\n",
       "           4.9685e-03, -4.9967e-03,  4.9598e-03, -4.9985e-03, -5.0016e-03,\n",
       "           7.6807e-25,  2.7538e-24,  8.2128e-25, -4.9776e-03],\n",
       "         [-5.4651e-44, -4.9531e-03,  4.9943e-03,  9.6690e-44,  1.1631e-43,\n",
       "           1.2191e-43, -9.8091e-45,  9.3887e-44, -4.9856e-03, -7.5670e-44,\n",
       "          -5.4651e-44, -5.0270e-03, -5.0248e-03,  4.9810e-03, -5.0468e-03,\n",
       "          -2.8026e-44, -1.0229e-43, -1.1210e-44, -4.9592e-03, -6.4460e-44,\n",
       "           1.2051e-43, -4.2039e-45,  5.0229e-03,  5.1848e-44,  4.9846e-03,\n",
       "           8.2677e-44, -1.4013e-45,  7.0065e-45, -2.2421e-44],\n",
       "         [ 4.9899e-03,  1.4013e-43, -6.0256e-44,  7.8473e-44,  6.7262e-44,\n",
       "          -4.9719e-03,  6.8664e-44,  5.0119e-03,  2.9427e-44, -4.9441e-03,\n",
       "           4.9957e-03,  8.8282e-44,  4.9468e-03, -4.9916e-03,  5.0605e-03,\n",
       "          -2.9427e-44,  5.6052e-45, -1.2612e-44, -4.9888e-03,  4.9834e-03,\n",
       "          -8.1275e-44, -2.6625e-44,  1.0229e-43, -8.4078e-44,  1.4013e-44,\n",
       "           5.0206e-03,  1.1631e-43,  5.0247e-03, -4.9722e-03]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-7.5368e-23, -4.9662e-03, -6.3776e-16,  4.4842e-44,  1.1771e-43,\n",
       "         -5.0435e-03,  4.9881e-03,  5.0259e-03,  4.9899e-03,  4.9615e-03],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-5.0045e-03, -3.3631e-44, -7.6300e-16,  8.2677e-44, -1.2191e-43,\n",
       "          -3.2777e-16, -4.4842e-44, -5.0019e-03,  2.1019e-44, -6.4460e-44]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0136], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.9012e-28],\n",
       "         [ 1.2892e-43],\n",
       "         [-7.8473e-44],\n",
       "         [ 1.2331e-43],\n",
       "         [ 1.2892e-43],\n",
       "         [-4.9930e-03],\n",
       "         [-3.5845e-28],\n",
       "         [-2.7111e-28],\n",
       "         [-3.7835e-44],\n",
       "         [ 1.9618e-44]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.7485e-02, -3.0846e-03, -5.3635e-17, -2.4219e-01, -9.8091e-45,\n",
       "         -2.3719e-02, -4.0169e-02, -2.7741e-02, -3.2230e-44, -2.3109e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 5.6779e-02,  1.1724e-03, -5.0302e-03,  5.5849e-02,  9.5288e-44,\n",
       "           7.4732e-02,  1.0678e-01,  8.6448e-02,  4.9757e-03,  1.8016e-02],\n",
       "         [ 1.6175e-01,  2.2758e-03,  7.0065e-44,  9.9699e-02,  1.0790e-43,\n",
       "           2.0983e-01,  3.3548e-01,  2.5465e-01, -1.4013e-45,  2.3406e-02],\n",
       "         [ 1.3162e-01,  2.9455e-03,  4.9727e-03,  2.5799e-02,  1.8217e-44,\n",
       "           1.3135e-01,  2.5282e-01,  1.6273e-01, -5.0454e-03,  1.7012e-03],\n",
       "         [ 2.2740e-03,  3.7941e-03, -4.9873e-03,  4.0126e-02, -4.9807e-03,\n",
       "          -6.2051e-04,  3.3691e-02,  7.6925e-03,  4.7644e-44,  6.6546e-03],\n",
       "         [ 2.1497e-01,  3.2626e-03,  1.3452e-43,  1.0262e-01, -1.0930e-43,\n",
       "           2.8285e-01,  4.0974e-01,  3.3042e-01, -5.0105e-03,  2.3508e-02],\n",
       "         [ 1.2249e-01,  1.1785e-03,  1.3593e-43,  6.2185e-02,  4.7644e-44,\n",
       "           1.4242e-01,  2.6626e-01,  1.7899e-01, -2.1019e-44,  1.8300e-02],\n",
       "         [ 1.3159e-02, -8.9683e-44,  1.3452e-43, -2.7230e-06,  4.2039e-45,\n",
       "           1.0664e-02,  2.0102e-02,  1.2043e-02, -1.1210e-43,  4.4842e-44],\n",
       "         [ 3.3539e-02,  2.9427e-44, -8.2677e-44,  1.4013e-45, -7.4269e-44,\n",
       "           2.7138e-02,  5.9690e-02,  3.3004e-02, -6.5861e-44,  3.9236e-44],\n",
       "         [ 1.9213e-01,  3.0671e-03, -9.6690e-44,  9.9039e-02, -8.4078e-45,\n",
       "           2.5355e-01,  3.9000e-01,  3.0337e-01,  5.4651e-44,  2.3845e-02],\n",
       "         [ 1.8108e-01,  2.9787e-03, -4.3440e-44,  9.4142e-02,  1.1771e-43,\n",
       "           2.3520e-01,  3.7785e-01,  2.8491e-01, -5.3249e-44,  2.1346e-02],\n",
       "         [ 1.5174e-01,  1.8149e-03, -6.4460e-44,  7.2293e-02,  4.9618e-03,\n",
       "           1.7437e-01,  3.0274e-01,  2.1285e-01,  4.9681e-03,  1.6590e-02],\n",
       "         [ 1.3215e-02,  5.2782e-04,  6.0256e-44,  8.0557e-02, -4.9993e-03,\n",
       "           3.6648e-02,  4.0200e-02,  4.2983e-02,  4.9763e-03,  2.0192e-02],\n",
       "         [ 1.0878e-01,  3.0347e-03, -7.2868e-44,  7.3373e-02, -7.5670e-44,\n",
       "           1.4163e-01,  2.3787e-01,  1.7389e-01, -1.3312e-43,  1.7059e-02],\n",
       "         [ 9.9662e-02,  1.3188e-03,  2.5223e-44,  8.1692e-02,  1.1631e-43,\n",
       "           1.3684e-01,  2.2605e-01,  1.6797e-01,  7.0065e-45,  2.5618e-02],\n",
       "         [ 6.3676e-02,  1.6757e-03,  1.2472e-43,  8.1082e-02, -4.9779e-03,\n",
       "           9.1028e-02,  1.4620e-01,  1.1160e-01,  3.9236e-44,  1.8126e-02],\n",
       "         [ 6.2709e-02,  8.2232e-04, -4.9813e-03,  6.4671e-02, -2.9427e-44,\n",
       "           8.4241e-02,  1.4534e-01,  1.0563e-01,  4.9756e-03,  1.3794e-02],\n",
       "         [ 4.5096e-02,  1.7123e-03,  2.1019e-44,  3.9688e-02,  4.3440e-44,\n",
       "           5.3438e-02,  1.2847e-01,  7.5013e-02, -7.8473e-44,  1.0255e-02],\n",
       "         [ 7.2910e-02,  5.2739e-04,  4.7644e-44,  4.4774e-02,  1.1070e-43,\n",
       "           9.3481e-02,  1.6633e-01,  1.1683e-01,  5.0157e-03,  1.3208e-02],\n",
       "         [ 7.1120e-02,  3.0711e-03, -1.3032e-43,  8.9263e-02, -6.8664e-44,\n",
       "           1.2214e-01,  1.8234e-01,  1.4924e-01,  4.2039e-44,  2.6000e-02],\n",
       "         [ 8.6791e-02, -2.8687e-05,  1.3312e-43,  4.1622e-02,  4.9942e-03,\n",
       "           1.0896e-01,  1.9618e-01,  1.3630e-01,  5.0447e-44,  1.2677e-02],\n",
       "         [ 1.0461e-01, -4.2487e-04, -1.2612e-43,  3.7729e-02, -1.1631e-43,\n",
       "           1.1581e-01,  2.0848e-01,  1.4286e-01, -4.9889e-03,  5.7123e-03],\n",
       "         [-1.0163e-02, -1.4013e-44, -3.0829e-44,  8.1075e-02, -3.9236e-44,\n",
       "           9.3773e-03,  5.3272e-03,  1.3014e-02, -6.7262e-44,  2.1835e-02],\n",
       "         [ 9.8476e-03,  3.7492e-04,  5.3249e-44,  5.3904e-02,  5.0277e-03,\n",
       "           1.4656e-02,  3.9787e-02,  2.2690e-02, -4.9894e-03,  1.3847e-02],\n",
       "         [ 1.4599e-01,  1.1348e-03, -1.0229e-43,  1.4390e-02, -6.1657e-44,\n",
       "           1.6042e-01,  2.9172e-01,  1.9828e-01, -4.9644e-03, -1.9164e-03],\n",
       "         [ 3.6472e-02, -1.7314e-04, -1.2892e-43,  4.0175e-02, -2.8026e-45,\n",
       "           4.0099e-02,  7.7804e-02,  5.0938e-02,  1.1771e-43,  8.5746e-03],\n",
       "         [-4.7335e-03, -1.4153e-43,  5.0067e-03,  3.8124e-02, -7.2868e-44,\n",
       "          -1.9277e-03,  1.2696e-02,  2.8064e-03, -1.4013e-45,  4.8154e-03],\n",
       "         [ 2.4038e-01,  2.3743e-03, -6.0256e-44,  2.9851e-02,  5.0180e-03,\n",
       "           2.4276e-01,  4.7573e-01,  3.0443e-01,  4.9587e-03,  4.1643e-03],\n",
       "         [ 9.6991e-02,  7.1286e-04, -9.6690e-44,  2.0624e-02, -5.0361e-03,\n",
       "           1.0858e-01,  2.0083e-01,  1.3494e-01, -9.3887e-44,  5.6543e-03],\n",
       "         [ 6.5133e-02,  3.2345e-03,  4.9684e-03,  9.1025e-02,  2.8026e-44,\n",
       "           1.1294e-01,  1.7449e-01,  1.3933e-01, -8.1275e-44,  2.7038e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2517, 0.8738, 0.6103, 0.4903, 0.6355, 0.6678, 0.0486, 0.1365, 0.7690,\n",
       "         0.8129, 0.7506, 0.4995, 0.6237, 0.5540, 0.6300, 0.6125, 0.5408, 0.3922,\n",
       "         0.5113, 0.4117, 0.5376, 0.5421, 0.4815, 0.5357, 0.4203, 0.4463, 1.0091,\n",
       "         0.3172, 0.5213], requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = list(sae.parameters())\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight tensor([[-5.0258e-03, -2.5123e-23, -5.0109e-03, -4.9885e-03,  5.0464e-03,\n",
      "         -3.3497e-23, -8.6881e-44, -5.0308e-03, -3.7745e-23, -3.8875e-23,\n",
      "         -2.5276e-23, -1.3300e-23, -4.9899e-03, -5.0077e-03, -2.7600e-23,\n",
      "         -2.5509e-23, -7.5368e-23,  4.9681e-03, -7.5368e-23, -7.1181e-23,\n",
      "          4.9792e-03, -5.0142e-03, -5.0130e-03, -5.0350e-03, -1.5769e-23,\n",
      "         -2.1021e-23, -5.0031e-03, -5.0307e-03,  5.0364e-03],\n",
      "        [ 1.3312e-43, -1.1070e-43,  4.9766e-03,  1.2191e-43, -8.4078e-45,\n",
      "         -5.7453e-44, -4.9352e-03,  7.9874e-44,  5.8855e-44,  9.1084e-44,\n",
      "          4.9702e-03, -1.0930e-43,  5.0257e-03,  6.1657e-44,  3.2230e-44,\n",
      "         -1.0650e-43,  4.9765e-03,  4.9686e-03,  9.8091e-44, -2.8026e-45,\n",
      "         -5.0116e-03, -4.9618e-03,  2.9427e-44, -6.8664e-44, -5.8855e-44,\n",
      "         -5.0188e-03, -8.5479e-44, -5.0014e-03,  5.0313e-03],\n",
      "        [-4.9726e-03, -2.1259e-16, -2.9427e-44, -1.0629e-16, -5.0207e-03,\n",
      "         -4.9761e-03,  4.9952e-03, -7.9720e-17, -5.0013e-03, -3.2896e-16,\n",
      "         -2.1388e-16, -1.1255e-16, -3.5369e-16, -4.2517e-16, -2.3355e-16,\n",
      "         -2.1586e-16, -5.0266e-03, -4.9796e-03, -6.3776e-16, -6.0233e-16,\n",
      "          2.8026e-44, -4.9944e-03, -4.9862e-03, -3.1129e-16, -1.3343e-16,\n",
      "         -1.7788e-16, -6.3776e-16, -4.9887e-03, -4.9592e-03],\n",
      "        [-4.9944e-03, -9.8091e-45,  4.9893e-03, -5.0269e-03,  5.6052e-45,\n",
      "         -4.2039e-45, -5.0059e-03,  5.0260e-03, -4.9826e-03, -5.0292e-03,\n",
      "          8.5479e-44, -1.2612e-44, -1.1210e-44,  4.9481e-03,  1.0510e-43,\n",
      "          5.0255e-03,  6.4460e-44,  1.2472e-43,  2.3822e-44, -4.9769e-03,\n",
      "         -5.0388e-03, -7.9874e-44, -7.1466e-44, -1.3032e-43, -4.9851e-03,\n",
      "         -5.0143e-03, -1.1771e-43, -5.0272e-03,  4.9850e-03],\n",
      "        [-4.9682e-03,  5.0471e-03,  4.9701e-03, -5.0161e-03,  4.9844e-03,\n",
      "          5.1848e-44,  3.2230e-44, -4.9594e-03, -4.9888e-03, -1.0229e-43,\n",
      "         -6.4460e-44, -4.9779e-03,  4.9882e-03,  1.0650e-43,  5.0398e-03,\n",
      "          1.4013e-45, -4.9982e-03,  1.3593e-43,  4.9861e-03,  4.9943e-03,\n",
      "         -4.9757e-03, -5.0021e-03,  1.1491e-43,  5.0100e-03,  1.1911e-43,\n",
      "          4.9650e-03, -5.6052e-44, -4.9794e-03, -5.0120e-03],\n",
      "        [-4.9842e-03, -5.4440e-21,  6.5861e-44,  4.9759e-03, -4.9827e-03,\n",
      "         -7.2586e-21, -4.9818e-03, -2.0415e-21, -5.0093e-03, -8.4241e-21,\n",
      "         -5.4772e-21,  5.0030e-03, -9.0574e-21, -4.9813e-03, -5.9807e-21,\n",
      "         -5.5277e-21, -4.9818e-03, -1.4055e-20,  4.9767e-03, -1.5425e-20,\n",
      "          3.9236e-44, -4.7344e-21, -4.1826e-21, -4.9887e-03, -3.4170e-21,\n",
      "         -5.0242e-03, -1.6332e-20,  5.0201e-03, -5.0336e-03],\n",
      "        [ 5.0151e-03, -5.6052e-44,  4.9701e-03, -4.9703e-03, -5.0350e-03,\n",
      "          8.4078e-45, -6.5861e-44,  4.9485e-03, -9.1084e-44,  5.0123e-03,\n",
      "         -1.8217e-44, -5.0309e-03, -4.9789e-03, -5.0762e-03,  4.9843e-03,\n",
      "         -4.6243e-44, -6.4460e-44,  5.0274e-03,  1.2612e-44, -5.0301e-03,\n",
      "          9.3887e-44,  6.4460e-44, -7.1466e-44, -5.0107e-03,  2.8026e-45,\n",
      "          8.6881e-44,  4.9757e-03,  4.9760e-03,  5.0596e-03],\n",
      "        [ 4.9950e-03,  9.1793e-25, -4.9897e-03,  4.5897e-25,  1.0014e-24,\n",
      "          1.2239e-24,  5.0332e-03,  3.4423e-25, -5.0092e-03,  4.9859e-03,\n",
      "          4.9587e-03,  4.8596e-25,  1.5272e-24, -4.9901e-03, -4.9899e-03,\n",
      "          9.3206e-25,  4.9757e-03,  2.3699e-24,  4.9811e-03, -4.9847e-03,\n",
      "          4.9685e-03, -4.9967e-03,  4.9598e-03, -4.9985e-03, -5.0016e-03,\n",
      "          7.6807e-25,  2.7538e-24,  8.2128e-25, -4.9776e-03],\n",
      "        [-5.4651e-44, -4.9531e-03,  4.9943e-03,  9.6690e-44,  1.1631e-43,\n",
      "          1.2191e-43, -9.8091e-45,  9.3887e-44, -4.9856e-03, -7.5670e-44,\n",
      "         -5.4651e-44, -5.0270e-03, -5.0248e-03,  4.9810e-03, -5.0468e-03,\n",
      "         -2.8026e-44, -1.0229e-43, -1.1210e-44, -4.9592e-03, -6.4460e-44,\n",
      "          1.2051e-43, -4.2039e-45,  5.0229e-03,  5.1848e-44,  4.9846e-03,\n",
      "          8.2677e-44, -1.4013e-45,  7.0065e-45, -2.2421e-44],\n",
      "        [ 4.9899e-03,  1.4013e-43, -6.0256e-44,  7.8473e-44,  6.7262e-44,\n",
      "         -4.9719e-03,  6.8664e-44,  5.0119e-03,  2.9427e-44, -4.9441e-03,\n",
      "          4.9957e-03,  8.8282e-44,  4.9468e-03, -4.9916e-03,  5.0605e-03,\n",
      "         -2.9427e-44,  5.6052e-45, -1.2612e-44, -4.9888e-03,  4.9834e-03,\n",
      "         -8.1275e-44, -2.6625e-44,  1.0229e-43, -8.4078e-44,  1.4013e-44,\n",
      "          5.0206e-03,  1.1631e-43,  5.0247e-03, -4.9722e-03]])\n",
      "fc1.bias tensor([-7.5368e-23, -4.9662e-03, -6.3776e-16,  4.4842e-44,  1.1771e-43,\n",
      "        -5.0435e-03,  4.9881e-03,  5.0259e-03,  4.9899e-03,  4.9615e-03])\n",
      "fc2.weight tensor([[-5.0045e-03, -3.3631e-44, -7.6300e-16,  8.2677e-44, -1.2191e-43,\n",
      "         -3.2777e-16, -4.4842e-44, -5.0019e-03,  2.1019e-44, -6.4460e-44]])\n",
      "fc2.bias tensor([-0.0136])\n",
      "fc3.weight tensor([[-1.9012e-28],\n",
      "        [ 1.2892e-43],\n",
      "        [-7.8473e-44],\n",
      "        [ 1.2331e-43],\n",
      "        [ 1.2892e-43],\n",
      "        [-4.9930e-03],\n",
      "        [-3.5845e-28],\n",
      "        [-2.7111e-28],\n",
      "        [-3.7835e-44],\n",
      "        [ 1.9618e-44]])\n",
      "fc3.bias tensor([-1.7485e-02, -3.0846e-03, -5.3635e-17, -2.4219e-01, -9.8091e-45,\n",
      "        -2.3719e-02, -4.0169e-02, -2.7741e-02, -3.2230e-44, -2.3109e-02])\n",
      "fc4.weight tensor([[ 5.6779e-02,  1.1724e-03, -5.0302e-03,  5.5849e-02,  9.5288e-44,\n",
      "          7.4732e-02,  1.0678e-01,  8.6448e-02,  4.9757e-03,  1.8016e-02],\n",
      "        [ 1.6175e-01,  2.2758e-03,  7.0065e-44,  9.9699e-02,  1.0790e-43,\n",
      "          2.0983e-01,  3.3548e-01,  2.5465e-01, -1.4013e-45,  2.3406e-02],\n",
      "        [ 1.3162e-01,  2.9455e-03,  4.9727e-03,  2.5799e-02,  1.8217e-44,\n",
      "          1.3135e-01,  2.5282e-01,  1.6273e-01, -5.0454e-03,  1.7012e-03],\n",
      "        [ 2.2740e-03,  3.7941e-03, -4.9873e-03,  4.0126e-02, -4.9807e-03,\n",
      "         -6.2051e-04,  3.3691e-02,  7.6925e-03,  4.7644e-44,  6.6546e-03],\n",
      "        [ 2.1497e-01,  3.2626e-03,  1.3452e-43,  1.0262e-01, -1.0930e-43,\n",
      "          2.8285e-01,  4.0974e-01,  3.3042e-01, -5.0105e-03,  2.3508e-02],\n",
      "        [ 1.2249e-01,  1.1785e-03,  1.3593e-43,  6.2185e-02,  4.7644e-44,\n",
      "          1.4242e-01,  2.6626e-01,  1.7899e-01, -2.1019e-44,  1.8300e-02],\n",
      "        [ 1.3159e-02, -8.9683e-44,  1.3452e-43, -2.7230e-06,  4.2039e-45,\n",
      "          1.0664e-02,  2.0102e-02,  1.2043e-02, -1.1210e-43,  4.4842e-44],\n",
      "        [ 3.3539e-02,  2.9427e-44, -8.2677e-44,  1.4013e-45, -7.4269e-44,\n",
      "          2.7138e-02,  5.9690e-02,  3.3004e-02, -6.5861e-44,  3.9236e-44],\n",
      "        [ 1.9213e-01,  3.0671e-03, -9.6690e-44,  9.9039e-02, -8.4078e-45,\n",
      "          2.5355e-01,  3.9000e-01,  3.0337e-01,  5.4651e-44,  2.3845e-02],\n",
      "        [ 1.8108e-01,  2.9787e-03, -4.3440e-44,  9.4142e-02,  1.1771e-43,\n",
      "          2.3520e-01,  3.7785e-01,  2.8491e-01, -5.3249e-44,  2.1346e-02],\n",
      "        [ 1.5174e-01,  1.8149e-03, -6.4460e-44,  7.2293e-02,  4.9618e-03,\n",
      "          1.7437e-01,  3.0274e-01,  2.1285e-01,  4.9681e-03,  1.6590e-02],\n",
      "        [ 1.3215e-02,  5.2782e-04,  6.0256e-44,  8.0557e-02, -4.9993e-03,\n",
      "          3.6648e-02,  4.0200e-02,  4.2983e-02,  4.9763e-03,  2.0192e-02],\n",
      "        [ 1.0878e-01,  3.0347e-03, -7.2868e-44,  7.3373e-02, -7.5670e-44,\n",
      "          1.4163e-01,  2.3787e-01,  1.7389e-01, -1.3312e-43,  1.7059e-02],\n",
      "        [ 9.9662e-02,  1.3188e-03,  2.5223e-44,  8.1692e-02,  1.1631e-43,\n",
      "          1.3684e-01,  2.2605e-01,  1.6797e-01,  7.0065e-45,  2.5618e-02],\n",
      "        [ 6.3676e-02,  1.6757e-03,  1.2472e-43,  8.1082e-02, -4.9779e-03,\n",
      "          9.1028e-02,  1.4620e-01,  1.1160e-01,  3.9236e-44,  1.8126e-02],\n",
      "        [ 6.2709e-02,  8.2232e-04, -4.9813e-03,  6.4671e-02, -2.9427e-44,\n",
      "          8.4241e-02,  1.4534e-01,  1.0563e-01,  4.9756e-03,  1.3794e-02],\n",
      "        [ 4.5096e-02,  1.7123e-03,  2.1019e-44,  3.9688e-02,  4.3440e-44,\n",
      "          5.3438e-02,  1.2847e-01,  7.5013e-02, -7.8473e-44,  1.0255e-02],\n",
      "        [ 7.2910e-02,  5.2739e-04,  4.7644e-44,  4.4774e-02,  1.1070e-43,\n",
      "          9.3481e-02,  1.6633e-01,  1.1683e-01,  5.0157e-03,  1.3208e-02],\n",
      "        [ 7.1120e-02,  3.0711e-03, -1.3032e-43,  8.9263e-02, -6.8664e-44,\n",
      "          1.2214e-01,  1.8234e-01,  1.4924e-01,  4.2039e-44,  2.6000e-02],\n",
      "        [ 8.6791e-02, -2.8687e-05,  1.3312e-43,  4.1622e-02,  4.9942e-03,\n",
      "          1.0896e-01,  1.9618e-01,  1.3630e-01,  5.0447e-44,  1.2677e-02],\n",
      "        [ 1.0461e-01, -4.2487e-04, -1.2612e-43,  3.7729e-02, -1.1631e-43,\n",
      "          1.1581e-01,  2.0848e-01,  1.4286e-01, -4.9889e-03,  5.7123e-03],\n",
      "        [-1.0163e-02, -1.4013e-44, -3.0829e-44,  8.1075e-02, -3.9236e-44,\n",
      "          9.3773e-03,  5.3272e-03,  1.3014e-02, -6.7262e-44,  2.1835e-02],\n",
      "        [ 9.8476e-03,  3.7492e-04,  5.3249e-44,  5.3904e-02,  5.0277e-03,\n",
      "          1.4656e-02,  3.9787e-02,  2.2690e-02, -4.9894e-03,  1.3847e-02],\n",
      "        [ 1.4599e-01,  1.1348e-03, -1.0229e-43,  1.4390e-02, -6.1657e-44,\n",
      "          1.6042e-01,  2.9172e-01,  1.9828e-01, -4.9644e-03, -1.9164e-03],\n",
      "        [ 3.6472e-02, -1.7314e-04, -1.2892e-43,  4.0175e-02, -2.8026e-45,\n",
      "          4.0099e-02,  7.7804e-02,  5.0938e-02,  1.1771e-43,  8.5746e-03],\n",
      "        [-4.7335e-03, -1.4153e-43,  5.0067e-03,  3.8124e-02, -7.2868e-44,\n",
      "         -1.9277e-03,  1.2696e-02,  2.8064e-03, -1.4013e-45,  4.8154e-03],\n",
      "        [ 2.4038e-01,  2.3743e-03, -6.0256e-44,  2.9851e-02,  5.0180e-03,\n",
      "          2.4276e-01,  4.7573e-01,  3.0443e-01,  4.9587e-03,  4.1643e-03],\n",
      "        [ 9.6991e-02,  7.1286e-04, -9.6690e-44,  2.0624e-02, -5.0361e-03,\n",
      "          1.0858e-01,  2.0083e-01,  1.3494e-01, -9.3887e-44,  5.6543e-03],\n",
      "        [ 6.5133e-02,  3.2345e-03,  4.9684e-03,  9.1025e-02,  2.8026e-44,\n",
      "          1.1294e-01,  1.7449e-01,  1.3933e-01, -8.1275e-44,  2.7038e-02]])\n",
      "fc4.bias tensor([0.2517, 0.8738, 0.6103, 0.4903, 0.6355, 0.6678, 0.0486, 0.1365, 0.7690,\n",
      "        0.8129, 0.7506, 0.4995, 0.6237, 0.5540, 0.6300, 0.6125, 0.5408, 0.3922,\n",
      "        0.5113, 0.4117, 0.5376, 0.5421, 0.4815, 0.5357, 0.4203, 0.4463, 1.0091,\n",
      "        0.3172, 0.5213])\n"
     ]
    }
   ],
   "source": [
    "for name, param in sae.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/baseball.pth'\n",
    "torch.save(sae.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2517, 0.8738, 0.6103, 0.4903, 0.6355, 0.6678, 0.0486, 0.1365, 0.7690,\n",
       "         0.8129, 0.7506, 0.4995, 0.6237, 0.5540, 0.6300, 0.6125, 0.5408, 0.3922,\n",
       "         0.5113, 0.4117, 0.5376, 0.5421, 0.4815, 0.5357, 0.4203, 0.4463, 1.0091,\n",
       "         0.3172, 0.5213],\n",
       "        [0.2517, 0.8738, 0.6103, 0.4903, 0.6355, 0.6678, 0.0486, 0.1365, 0.7690,\n",
       "         0.8129, 0.7506, 0.4995, 0.6237, 0.5540, 0.6300, 0.6125, 0.5408, 0.3922,\n",
       "         0.5113, 0.4117, 0.5376, 0.5421, 0.4815, 0.5357, 0.4203, 0.4463, 1.0091,\n",
       "         0.3172, 0.5213],\n",
       "        [0.2517, 0.8738, 0.6103, 0.4903, 0.6355, 0.6678, 0.0486, 0.1365, 0.7690,\n",
       "         0.8129, 0.7506, 0.4995, 0.6237, 0.5540, 0.6300, 0.6125, 0.5408, 0.3922,\n",
       "         0.5113, 0.4117, 0.5376, 0.5421, 0.4815, 0.5357, 0.4203, 0.4463, 1.0091,\n",
       "         0.3172, 0.5213],\n",
       "        [0.2517, 0.8738, 0.6103, 0.4903, 0.6355, 0.6678, 0.0486, 0.1365, 0.7690,\n",
       "         0.8129, 0.7506, 0.4995, 0.6237, 0.5540, 0.6300, 0.6125, 0.5408, 0.3922,\n",
       "         0.5113, 0.4117, 0.5376, 0.5421, 0.4815, 0.5357, 0.4203, 0.4463, 1.0091,\n",
       "         0.3172, 0.5213],\n",
       "        [0.2517, 0.8738, 0.6103, 0.4903, 0.6355, 0.6678, 0.0486, 0.1365, 0.7690,\n",
       "         0.8129, 0.7506, 0.4995, 0.6237, 0.5540, 0.6300, 0.6125, 0.5408, 0.3922,\n",
       "         0.5113, 0.4117, 0.5376, 0.5421, 0.4815, 0.5357, 0.4203, 0.4463, 1.0091,\n",
       "         0.3172, 0.5213],\n",
       "        [0.2517, 0.8738, 0.6103, 0.4903, 0.6355, 0.6678, 0.0486, 0.1365, 0.7690,\n",
       "         0.8129, 0.7506, 0.4995, 0.6237, 0.5540, 0.6300, 0.6125, 0.5408, 0.3922,\n",
       "         0.5113, 0.4117, 0.5376, 0.5421, 0.4815, 0.5357, 0.4203, 0.4463, 1.0091,\n",
       "         0.3172, 0.5213]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = sae(test_set_1)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1463, 0.7667, 0.1000, 0.0000, 0.5455, 0.4444, 0.0000, 0.0000, 0.6294,\n",
       "         0.6681, 0.5488, 0.8824, 0.4629, 0.6667, 0.7324, 0.7538, 0.3653, 0.6587,\n",
       "         0.3386, 0.7037, 0.3023, 0.4607, 0.0000, 0.2381, 0.6418, 0.7007, 1.0000,\n",
       "         0.6512, 0.1176],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0455, 0.7778, 1.0000, 1.0000, 0.0521,\n",
       "         0.0733, 0.1402, 0.2353, 0.0000, 0.0222, 0.1690, 0.1538, 0.1301, 0.6779,\n",
       "         0.0394, 0.6667, 0.9535, 1.0000, 0.7927, 0.6190, 0.4965, 0.7211, 1.0000,\n",
       "         0.2982, 0.1373],\n",
       "        [0.2195, 0.8667, 0.0000, 0.0000, 0.5909, 0.4444, 0.0000, 0.0000, 0.6636,\n",
       "         0.7414, 0.6280, 0.4118, 0.6157, 1.0000, 0.7465, 0.7385, 0.7169, 1.0000,\n",
       "         0.5984, 1.0000, 0.4419, 0.7438, 0.6098, 0.2262, 0.5816, 0.5476, 1.0000,\n",
       "         1.0000, 0.0000],\n",
       "        [0.0000, 0.5667, 0.2000, 0.1667, 0.1818, 0.7778, 0.0000, 0.0000, 0.3869,\n",
       "         0.4052, 0.4390, 0.2941, 0.1878, 0.0889, 0.3803, 0.3846, 0.0000, 0.1635,\n",
       "         0.0000, 0.1667, 0.6977, 0.4989, 0.4878, 0.4286, 0.4078, 0.4830, 1.0000,\n",
       "         0.3834, 0.2549],\n",
       "        [0.7561, 0.0000, 0.0000, 0.0000, 0.0000, 0.2222, 0.8276, 0.2500, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0480, 0.0000, 0.0000, 0.0000, 0.9452, 0.8317,\n",
       "         0.9134, 0.8889, 0.2674, 0.4494, 0.7073, 1.0000, 0.0177, 0.0306, 1.0000,\n",
       "         0.1217, 0.1176],\n",
       "        [0.2439, 0.9000, 0.0000, 0.0000, 0.5455, 0.8889, 0.0000, 0.0000, 0.7613,\n",
       "         0.7989, 0.7805, 0.5294, 0.6114, 0.1778, 0.6479, 0.6154, 0.4886, 0.0000,\n",
       "         0.4724, 0.0000, 0.5698, 0.3506, 0.5976, 0.4107, 0.3475, 0.3673, 1.0000,\n",
       "         0.5173, 0.9020]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1387, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = criterion(test_set_1,outputs)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
